{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPyxCQYoMBLtt1Ayto5VwZB"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12785947,"sourceType":"datasetVersion","datasetId":8083584},{"sourceId":12786616,"sourceType":"datasetVersion","datasetId":8084045},{"sourceId":12788160,"sourceType":"datasetVersion","datasetId":8085102},{"sourceId":12788107,"sourceType":"datasetVersion","datasetId":8085067}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install optuna\n!pip install gpytorch","metadata":{"id":"xqXMutdkGoE3","executionInfo":{"status":"ok","timestamp":1755367912144,"user_tz":-120,"elapsed":110735,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"outputId":"7ad11888-3c2e-47fb-954b-225bb337460b","trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:44.266653Z","iopub.execute_input":"2025-08-21T19:14:44.267205Z","iopub.status.idle":"2025-08-21T19:14:50.459411Z","shell.execute_reply.started":"2025-08-21T19:14:44.267179Z","shell.execute_reply":"2025-08-21T19:14:50.458673Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: gpytorch in /usr/local/lib/python3.11/dist-packages (1.14)\nRequirement already satisfied: jaxtyping in /usr/local/lib/python3.11/dist-packages (from gpytorch) (0.3.2)\nRequirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.3.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.2.2)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.15.3)\nRequirement already satisfied: linear-operator>=0.6 in /usr/local/lib/python3.11/dist-packages (from gpytorch) (0.6)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from linear-operator>=0.6->gpytorch) (2.6.0+cu124)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.6.0->gpytorch) (1.26.4)\nRequirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping->gpytorch) (0.1.7)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (1.13.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->linear-operator>=0.6->gpytorch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2024.2.0)\n","output_type":"stream"}],"execution_count":173},{"cell_type":"code","source":"from sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nfrom functools import reduce\nimport os\nimport joblib\nimport pickle\nfrom pathlib import Path\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nimport gpytorch\nfrom gpytorch.kernels import MaternKernel, PeriodicKernel, LinearKernel, ScaleKernel, MultitaskKernel, RBFKernel, AdditiveKernel\nfrom gpytorch.models import ApproximateGP\nfrom gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy, MultitaskVariationalStrategy, LMCVariationalStrategy\nfrom gpytorch.distributions import MultitaskMultivariateNormal\nfrom gpytorch.likelihoods import MultitaskGaussianLikelihood\nfrom gpytorch.mlls import VariationalELBO\nfrom gpytorch.means import ConstantMean\n\nfrom joblib import Parallel, delayed\nimport gc\nfrom scipy.stats import multivariate_normal\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom typing import Tuple\nfrom functools import partial\nfrom linear_operator.utils.errors import NotPSDError","metadata":{"id":"lji1yiK7FroQ","executionInfo":{"status":"ok","timestamp":1755367921858,"user_tz":-120,"elapsed":9699,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:50.461268Z","iopub.execute_input":"2025-08-21T19:14:50.461672Z","iopub.status.idle":"2025-08-21T19:14:50.469307Z","shell.execute_reply.started":"2025-08-21T19:14:50.461640Z","shell.execute_reply":"2025-08-21T19:14:50.468478Z"}},"outputs":[],"execution_count":174},{"cell_type":"code","source":"#Laden der Rowwise Daten da bessser geeignet\nrowwiseDf = pd.read_csv(\"/kaggle/input/rowwisedfcsv/rowwiseDf.csv\")","metadata":{"id":"mytIGQ1gF3fl","executionInfo":{"status":"ok","timestamp":1755367928007,"user_tz":-120,"elapsed":6009,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:50.469944Z","iopub.execute_input":"2025-08-21T19:14:50.470246Z","iopub.status.idle":"2025-08-21T19:14:55.461984Z","shell.execute_reply.started":"2025-08-21T19:14:50.470223Z","shell.execute_reply":"2025-08-21T19:14:55.461431Z"}},"outputs":[],"execution_count":175},{"cell_type":"code","source":"gpytorch.settings.cholesky_jitter._global_default = 1e-2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:55.463842Z","iopub.execute_input":"2025-08-21T19:14:55.464083Z","iopub.status.idle":"2025-08-21T19:14:55.467735Z","shell.execute_reply.started":"2025-08-21T19:14:55.464065Z","shell.execute_reply":"2025-08-21T19:14:55.466990Z"}},"outputs":[],"execution_count":176},{"cell_type":"code","source":"#Input Parameters\nrandomState= 21\nnJobs= -1\nnTrials= 20\n#topK= 3\nnotebook_dir = Path().resolve()\nstoragePath = notebook_dir.parent / \"data\" / \"rowWiseGPModel\"\nStations= [\"Erfurt-Weimar\", \"Schmücke\", \"Eisenach\", \"Artern\", \"Neuhaus am Rennweg\",\"Meiningen\", \"Leinefelde\", \"Osterfeld\"]\nReducedJahre= 5\nminInducing= 1000\nSAVE_DIR = \"/kaggle/working/gp_checkpoints\"\n\nselected_Station = [\"LastYear\", \"Erfurt-Weimar\"]#, \"Schmücke\", \"Eisenach\", \"Artern\"] #LastYear wenn letztes Jahr\nfeatures = ['Stationshoehe','geoBreite','geoLaenge', 'hour', 'day_of_year', 'time_hours']\ntargets = ['TT_TU','RF_TU','  R1','  P0','   F']","metadata":{"id":"6ZSzoy1pF0Ti","executionInfo":{"status":"ok","timestamp":1755367921962,"user_tz":-120,"elapsed":68,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:55.468422Z","iopub.execute_input":"2025-08-21T19:14:55.468595Z","iopub.status.idle":"2025-08-21T19:14:55.482302Z","shell.execute_reply.started":"2025-08-21T19:14:55.468581Z","shell.execute_reply":"2025-08-21T19:14:55.481626Z"}},"outputs":[],"execution_count":177},{"cell_type":"code","source":"rowwiseDf['MESS_DATUM']= pd.to_datetime(rowwiseDf['MESS_DATUM'])\n\nrowwiseDf['day_of_year']= rowwiseDf['MESS_DATUM'].dt.dayofyear","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:55.483066Z","iopub.execute_input":"2025-08-21T19:14:55.483402Z","iopub.status.idle":"2025-08-21T19:14:55.883776Z","shell.execute_reply.started":"2025-08-21T19:14:55.483378Z","shell.execute_reply":"2025-08-21T19:14:55.883034Z"}},"outputs":[],"execution_count":178},{"cell_type":"code","source":"rowwiseDf.columns","metadata":{"id":"3xEkeXFBF5K1","executionInfo":{"status":"ok","timestamp":1755367928039,"user_tz":-120,"elapsed":30,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"outputId":"9ed021b7-628d-4fb2-f206-4166e71734af","trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:55.884561Z","iopub.execute_input":"2025-08-21T19:14:55.884805Z","iopub.status.idle":"2025-08-21T19:14:55.890142Z","shell.execute_reply.started":"2025-08-21T19:14:55.884785Z","shell.execute_reply":"2025-08-21T19:14:55.889523Z"}},"outputs":[{"execution_count":179,"output_type":"execute_result","data":{"text/plain":"Index(['MESS_DATUM', 'STATIONS_ID', 'TT_TU', 'RF_TU', '  R1', 'RS_IND', 'WRTR',\n       '   P', '  P0', '   F', '   D', 'Stationshoehe', 'geoBreite',\n       'geoLaenge', 'Stationsname', 'hour', 'day', 'month', 'hour_sin',\n       'hour_cos', 'month_sin', 'month_cos', 'day_of_year_sin',\n       'day_of_year_cos', 'day_of_year'],\n      dtype='object')"},"metadata":{}}],"execution_count":179},{"cell_type":"code","source":"distanceDf= rowwiseDf[['geoBreite', 'geoLaenge', 'Stationsname', 'STATIONS_ID']].drop_duplicates()","metadata":{"id":"L-D96LjVF6yH","executionInfo":{"status":"ok","timestamp":1755367928935,"user_tz":-120,"elapsed":898,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:55.890979Z","iopub.execute_input":"2025-08-21T19:14:55.891209Z","iopub.status.idle":"2025-08-21T19:14:56.085408Z","shell.execute_reply.started":"2025-08-21T19:14:55.891193Z","shell.execute_reply":"2025-08-21T19:14:56.084841Z"}},"outputs":[],"execution_count":180},{"cell_type":"code","source":"lat1 = None\nlon1 = None\nfor _, row in distanceDf.iterrows():\n    if row['Stationsname'] == 'Erfurt-Weimar':\n        lat1 = np.radians(row['geoBreite'])\n        lon1 = np.radians(row['geoLaenge'])\n        break  # reicht, wenn wir den ersten passenden Eintrag haben\n\n# 2. Distanz für alle anderen Stationen berechnen\ndistances = []\nfor _, row in distanceDf.iterrows():\n    if row['Stationsname'] == 'Erfurt-Weimar':\n        continue\n\n    lat2 = np.radians(row['geoBreite'])\n    lon2 = np.radians(row['geoLaenge'])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n\n    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n    distance = 2 * 6371 * np.arcsin(np.sqrt(a))  # in km\n\n    distances.append({\n        'Stationsname': row['Stationsname'],\n        'distance_km': distance\n    })\n\n# 3. In DataFrame umwandeln und sortieren\ndistance_result = pd.DataFrame(distances).sort_values('distance_km')\nprint(distance_result)","metadata":{"id":"X8GTb-wKF8ij","executionInfo":{"status":"ok","timestamp":1755367929023,"user_tz":-120,"elapsed":67,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"outputId":"796c01fd-c2e0-4876-8730-e0de0329e6fd","trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.086210Z","iopub.execute_input":"2025-08-21T19:14:56.086478Z","iopub.status.idle":"2025-08-21T19:14:56.098843Z","shell.execute_reply.started":"2025-08-21T19:14:56.086451Z","shell.execute_reply":"2025-08-21T19:14:56.098023Z"}},"outputs":[{"name":"stdout","text":"            Stationsname  distance_km\n11              Schmücke    38.908361\n17              Eisenach    41.949378\n9                 Artern    49.275834\n15    Neuhaus am Rennweg    55.036985\n12             Meiningen    62.326012\n8             Leinefelde    64.219198\n14             Osterfeld    68.707104\n16               Schleiz    75.136254\n0   Lautertal-Oberlauter    75.202795\n13            Harzgerode    75.396944\n10         Gera-Leumnitz    82.636570\n1              Braunlage    86.024839\n5          Hersfeld, Bad    86.966964\n4            Wasserkuppe    89.710348\n2              Göttingen    90.844191\n7            Wernigerode    96.827360\n3                    Hof    98.609755\n6                 Plauen    99.376594\n","output_type":"stream"}],"execution_count":181},{"cell_type":"code","source":"#reduziere Daten größe damit Modell berechnbar bleibt\nreducedDf= rowwiseDf.copy()\nreducedDf['MESS_DATUM']= pd.to_datetime(reducedDf['MESS_DATUM'])\n\nmaxDate= reducedDf['MESS_DATUM'].max()\ncutoffDate= maxDate - pd.DateOffset(years= ReducedJahre)\n\nreducedDf= reducedDf[(reducedDf['Stationsname'].isin(Stations)) & (reducedDf['MESS_DATUM'] >= cutoffDate)]","metadata":{"id":"4G59MUkTGCAc","executionInfo":{"status":"ok","timestamp":1755367930801,"user_tz":-120,"elapsed":1762,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.101148Z","iopub.execute_input":"2025-08-21T19:14:56.101344Z","iopub.status.idle":"2025-08-21T19:14:56.311613Z","shell.execute_reply.started":"2025-08-21T19:14:56.101329Z","shell.execute_reply":"2025-08-21T19:14:56.310820Z"}},"outputs":[],"execution_count":182},{"cell_type":"code","source":"reducedDf['time_hours'] = (reducedDf['MESS_DATUM'] - reducedDf['MESS_DATUM'].min()).dt.total_seconds() / 3600","metadata":{"id":"IKiXsplPGB7_","executionInfo":{"status":"ok","timestamp":1755367930804,"user_tz":-120,"elapsed":1,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.312476Z","iopub.execute_input":"2025-08-21T19:14:56.312733Z","iopub.status.idle":"2025-08-21T19:14:56.323453Z","shell.execute_reply.started":"2025-08-21T19:14:56.312708Z","shell.execute_reply":"2025-08-21T19:14:56.322849Z"}},"outputs":[],"execution_count":183},{"cell_type":"code","source":"#month wird gedropt da hoch koriliert mit day of year","metadata":{"id":"zA9cDuvTGHGR","executionInfo":{"status":"ok","timestamp":1755367930807,"user_tz":-120,"elapsed":1,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.324284Z","iopub.execute_input":"2025-08-21T19:14:56.324579Z","iopub.status.idle":"2025-08-21T19:14:56.333651Z","shell.execute_reply.started":"2025-08-21T19:14:56.324561Z","shell.execute_reply":"2025-08-21T19:14:56.332984Z"}},"outputs":[],"execution_count":184},{"cell_type":"code","source":"reducedDf= reducedDf.drop(columns= ['STATIONS_ID', 'RS_IND', 'WRTR','   P', '   D', 'day', 'month', 'month_sin', 'month_cos', 'hour_sin', 'hour_cos', 'day_of_year_sin', 'day_of_year_cos'])","metadata":{"id":"ql7eYZYsGJMv","executionInfo":{"status":"ok","timestamp":1755367930813,"user_tz":-120,"elapsed":4,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.334419Z","iopub.execute_input":"2025-08-21T19:14:56.334607Z","iopub.status.idle":"2025-08-21T19:14:56.356004Z","shell.execute_reply.started":"2025-08-21T19:14:56.334592Z","shell.execute_reply":"2025-08-21T19:14:56.355347Z"}},"outputs":[],"execution_count":185},{"cell_type":"code","source":"reducedDf.columns","metadata":{"id":"DLbRNsPFGLVr","executionInfo":{"status":"ok","timestamp":1755367930843,"user_tz":-120,"elapsed":18,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"outputId":"1fe5c5f3-34d1-43f8-b05d-f7511601e188","trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.356622Z","iopub.execute_input":"2025-08-21T19:14:56.356795Z","iopub.status.idle":"2025-08-21T19:14:56.361427Z","shell.execute_reply.started":"2025-08-21T19:14:56.356780Z","shell.execute_reply":"2025-08-21T19:14:56.360610Z"}},"outputs":[{"execution_count":186,"output_type":"execute_result","data":{"text/plain":"Index(['MESS_DATUM', 'TT_TU', 'RF_TU', '  R1', '  P0', '   F', 'Stationshoehe',\n       'geoBreite', 'geoLaenge', 'Stationsname', 'hour', 'day_of_year',\n       'time_hours'],\n      dtype='object')"},"metadata":{}}],"execution_count":186},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.362213Z","iopub.execute_input":"2025-08-21T19:14:56.362408Z","iopub.status.idle":"2025-08-21T19:14:56.375981Z","shell.execute_reply.started":"2025-08-21T19:14:56.362394Z","shell.execute_reply":"2025-08-21T19:14:56.375483Z"}},"outputs":[],"execution_count":187},{"cell_type":"code","source":"os.makedirs(SAVE_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.376649Z","iopub.execute_input":"2025-08-21T19:14:56.376853Z","iopub.status.idle":"2025-08-21T19:14:56.387610Z","shell.execute_reply.started":"2025-08-21T19:14:56.376830Z","shell.execute_reply":"2025-08-21T19:14:56.387096Z"}},"outputs":[],"execution_count":188},{"cell_type":"code","source":"for station in selected_Station:\n    os.makedirs(SAVE_DIR + '/' + station, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.388300Z","iopub.execute_input":"2025-08-21T19:14:56.388523Z","iopub.status.idle":"2025-08-21T19:14:56.400346Z","shell.execute_reply.started":"2025-08-21T19:14:56.388499Z","shell.execute_reply":"2025-08-21T19:14:56.399777Z"}},"outputs":[],"execution_count":189},{"cell_type":"code","source":"class MultitaskGPModel(ApproximateGP):\n    def __init__(self, num_latents, num_tasks, inducing_points, nu_height, nu_lonlat, daily_period, yearly_period):\n        variational_distribution= gpytorch.variational.CholeskyVariationalDistribution(\n            inducing_points.size(-2), batch_shape=torch.Size([num_latents])\n        )\n\n        variational_strategy= gpytorch.variational.LMCVariationalStrategy(\n            gpytorch.variational.VariationalStrategy(\n                self, inducing_points, variational_distribution, learn_inducing_locations=True\n            ),\n            num_tasks= num_tasks,\n            num_latents= num_latents,\n            latent_dim= -1\n        )\n\n        super().__init__(variational_strategy)\n\n        self.mean_module= gpytorch.means.ConstantMean(batch_shape= torch.Size([num_latents]))\n\n        self.daily_kernel= PeriodicKernel(period_length=daily_period, batch_shape= torch.Size([num_latents]), active_dim=[3])\n        self.yearly_kernel= PeriodicKernel(period_length=yearly_period, batch_shape= torch.Size([num_latents]), active_dim=[4])\n        self.hight_kernel= MaternKernel(nu=nu_height, batch_shape= torch.Size([num_latents]), active_dim=[0])\n        self.lonLat_kernel= MaternKernel(nu=nu_lonlat, batch_shape= torch.Size([num_latents]), active_dim=[1,2])\n        self.conter_kernel= RBFKernel(batch_shape= torch.Size([num_latents]), active_dim=[5])\n        \n        self.covar_module= ScaleKernel(\n            AdditiveKernel(\n                self.daily_kernel,\n                self.yearly_kernel,\n                self.lonLat_kernel,\n                self.hight_kernel,\n                self.conter_kernel\n            ),\n            batch_shape= torch.Size([num_latents])\n        )\n\n    def forward(self, x):\n        mean_x= self.mean_module(x)\n        covar_x= self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.400966Z","iopub.execute_input":"2025-08-21T19:14:56.401204Z","iopub.status.idle":"2025-08-21T19:14:56.414221Z","shell.execute_reply.started":"2025-08-21T19:14:56.401188Z","shell.execute_reply":"2025-08-21T19:14:56.413545Z"}},"outputs":[],"execution_count":190},{"cell_type":"code","source":"def objective(trial, X_train_np, y_train_np, X_val_np, y_val_np,\n              num_tasks=5, device=device, save_dir=SAVE_DIR, batch_size=512):\n    # Optuna hyperparams (add or remove as you like)\n    num_inducing = 1000\n    nu_lonlat = 1.5\n    nu_height = 0.5\n    daily_period = 24\n    yearly_period = 365.25\n    lr = 0.0037427697892870536\n    training_iter = 129\n    num_latents = 6\n\n    # Create inducing points (from X_sub)\n    subset_idx = np.random.choice(X_train_np.shape[0], min(10000, X_train_np.shape[0]), replace=False)\n    X_kmeans_np = X_train_np[subset_idx]\n\n    kmeans = KMeans(n_clusters=num_inducing, n_init=10, random_state=randomState)\n    kmeans.fit(X_kmeans_np)\n    inducing_points = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32).to(device)\n\n    # Convert to tensors\n    X_sub = torch.tensor(X_train_np, dtype=torch.float32).to(device)\n    y_sub = torch.tensor(y_train_np, dtype=torch.float32).to(device)\n\n    dataset = TensorDataset(X_sub, y_sub)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    \n    # Build model & likelihood\n    # Pass period_lengths into kernel by setting them after init\n    model = MultitaskGPModel(\n        inducing_points=inducing_points,\n        num_tasks=num_tasks,\n        num_latents= num_latents,\n        nu_lonlat=nu_lonlat,\n        nu_height=nu_height,\n        daily_period= daily_period,\n        yearly_period= yearly_period\n    ).to(device)\n\n    likelihood = MultitaskGaussianLikelihood(num_tasks=num_tasks).to(device)\n\n    # ⬇️ Multi-GPU Wrapper\n    if torch.cuda.device_count() > 1:\n        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n        model = torch.nn.DataParallel(model)\n        likelihood = torch.nn.DataParallel(likelihood)\n        \n    # initialize noise to a sensible positive value to help stability\n    try:\n        likelihood.noise_covar.initialize(noise=0.05)\n    except Exception:\n        pass\n\n    model.train()\n    likelihood.train()\n\n    optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': likelihood.parameters()}], lr=lr)\n\n    if isinstance(model, torch.nn.DataParallel):\n        mll = VariationalELBO(likelihood.module, model.module, num_data=X_sub.shape[0])\n    else:\n        mll = VariationalELBO(likelihood, model, num_data=X_sub.shape[0])\n    #mll = VariationalELBO(likelihood, model, num_data=X_sub.shape[0])\n\n    best_loss = float(\"inf\")\n    accumulation_steps = 2 \n    try:\n        for it in range(training_iter):\n            epoch_loss = 0.0\n            scaler = GradScaler()\n            for X_batch, y_batch in loader:\n                optimizer.zero_grad()\n                with autocast():\n                    # increase jitter during training for robustness\n                    with gpytorch.settings.cholesky_jitter(1e-3):\n                        output = model(X_batch)\n                        loss = -mll(output, y_batch)\n                # catch NaN\n                if not torch.isfinite(loss):\n                    raise RuntimeError(\"Loss NaN or INF\")\n\n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n                #loss.backward()\n                #optimizer.step()\n                epoch_loss += loss.item() * X_batch.size(0)\n\n            # mittlere Epoche\n            epoch_loss /= len(dataset)\n            if epoch_loss < best_loss:\n                best_loss = epoch_loss\n\n            del X_batch, y_batch, output, loss\n            torch.cuda.empty_cache()\n            gc.collect()\n\n        # Validation\n        model.eval()\n        likelihood.eval()\n        total_val_loss = 0.0\n        with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.cholesky_jitter(1e-3):\n            X_val = torch.tensor(X_val_np, dtype=torch.float32).to(device)\n            y_val = torch.tensor(y_val_np, dtype=torch.float32).to(device)\n            for start_idx in range(0, X_val.shape[0], batch_size):\n                end_idx = min(start_idx + batch_size, X_val.shape[0])\n                X_batch = torch.tensor(X_val_np[start_idx:end_idx], dtype=torch.float32).to(device)\n                y_batch = torch.tensor(y_val_np[start_idx:end_idx], dtype=torch.float32).to(device)\n                \n                # Vorwärtsdurchlauf und Verlustberechnung\n                val_output = model(X_batch)\n                val_loss = -mll(val_output, y_batch).item()\n        \n                # Addiere den Verlust für diese Batch\n                total_val_loss += val_loss * X_batch.size(0)\n        \n            # Berechne den durchschnittlichen Verlust über alle Batches\n            average_val_loss = total_val_loss / X_val.shape[0]\n    \n    except NotPSDError as e:\n        # numerical issue with PSD — return a large loss so Optuna avoids such hyperparams\n        print(\"NotPSDError in trial:\", e)\n        return 1e6\n    except Exception as e:\n        print(\"Exception during training:\", e)\n        return 1e6\n\n    # Save model state for this trial\n    model_path = os.path.join(save_dir, f\"model_trial_{trial.number}.pt\")\n    lik_path = os.path.join(save_dir, f\"likelihood_trial_{trial.number}.pt\")\n    if isinstance(model, torch.nn.DataParallel):\n        torch.save(model.module.state_dict(), model_path)\n        # likelihood ist auch DataParallel → also auch .module\n        torch.save(likelihood.module.state_dict(), lik_path)\n    else:\n        torch.save(model.state_dict(), model_path)\n        torch.save(likelihood.state_dict(), lik_path)\n    print(f\"[Trial {trial.number}] saved to {model_path}\")\n\n    return average_val_loss","metadata":{"id":"oAOu92pdzJ4x","executionInfo":{"status":"ok","timestamp":1755367931422,"user_tz":-120,"elapsed":46,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.414846Z","iopub.execute_input":"2025-08-21T19:14:56.415052Z","iopub.status.idle":"2025-08-21T19:14:56.433428Z","shell.execute_reply.started":"2025-08-21T19:14:56.415030Z","shell.execute_reply":"2025-08-21T19:14:56.432911Z"}},"outputs":[],"execution_count":191},{"cell_type":"code","source":"for station in selected_Station:\n    if station == 'LastYear':\n        # Split nach Datum: letzte 10% als Test\n        maxDate = reducedDf['MESS_DATUM'].max()\n        cutoffDate = maxDate - pd.DateOffset(years=1)\n        df_test = reducedDf[reducedDf['MESS_DATUM'] >= cutoffDate]\n        df_train = reducedDf[reducedDf['MESS_DATUM'] < cutoffDate]\n        station_name = \"None\"\n    else:\n        # Split nach Station\n        df_test = reducedDf[reducedDf['Stationsname'] == station]\n        df_train = reducedDf[reducedDf['Stationsname'] != station]\n        station_name = station\n\n    drop_cols = ['MESS_DATUM', 'Stationsname']\n    df_train = df_train.drop(columns=drop_cols, errors='ignore')\n    df_test = df_test.drop(columns=drop_cols, errors='ignore')\n\n    X_train= df_train[features].values.astype(np.float32)\n    y_train= df_train[targets].values.astype(np.float32)\n\n    X_test= df_test[features].values.astype(np.float32)\n    y_test= df_test[targets].values.astype(np.float32)\n\n    scalerX = StandardScaler()\n    X_train_np = scalerX.fit_transform(X_train)\n    X_val_np = scalerX.transform(X_test)\n    scalerY = StandardScaler()\n    y_train_np = scalerY.fit_transform(y_train)\n    y_val_np = scalerY.transform(y_test)\n\n    objective_fn = partial(\n        objective,\n        X_train_np=X_train_np,\n        y_train_np=y_train_np,\n        X_val_np=X_val_np,\n        y_val_np=y_val_np,\n        num_tasks= len(targets),          # Anzahl Output-Tasks\n        device=device,\n        save_dir=SAVE_DIR + '/' + station\n    )\n\n    storage_path = f\"sqlite:///{SAVE_DIR}/{station}.db\"\n    study = optuna.create_study(\n        study_name=\"sparse_gp_weather\",\n        storage=storage_path,\n        direction=\"minimize\",\n        load_if_exists=True,\n    )\n    study.optimize(objective_fn, n_trials=1)# Optuna-Studie mit persistentem Speicher","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T19:14:56.434284Z","iopub.execute_input":"2025-08-21T19:14:56.434475Z","execution_failed":"2025-08-21T19:19:55.942Z"}},"outputs":[{"name":"stderr","text":"[I 2025-08-21 19:14:56,578] Using an existing study with name 'sparse_gp_weather' instead of creating a new one.\n/tmp/ipykernel_36/2268218835.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n/tmp/ipykernel_36/2268218835.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"}],"execution_count":null}]}