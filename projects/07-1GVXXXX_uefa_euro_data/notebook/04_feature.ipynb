{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78f07b2-51dd-471e-9561-f41b0679b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa709c-f558-4990-8a54-39a60bd43555",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"..\\results\\player_stats_clean.csv\"\n",
    "\n",
    "# Mindest-Vollständigkeit pro Spalte z. B. 0.7 = 70%\n",
    "COMPLETENESS_MIN = 0.70\n",
    "\n",
    "# Korrelation (absolut) ab der Redundanzen entfernen\n",
    "CORR_MAX = 0.90\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdaef6e4-eca6-475f-84b4-76618d28fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalten definieren und was niemals als Feature genutzt wird\n",
    "drop_exact = {\n",
    "    'Player','Pos','Squad','Team','Nation','Comp','Season','League','Rk',\n",
    "    'Born','Matches','Match','Date','Venue','Round','Opponent','ID','PlayerID'\n",
    "}\n",
    "# Alles \"Unnamed\" etc. raus, auf Nummer sicher gehen\n",
    "drop_prefixes = ('Unnamed',)\n",
    "\n",
    "meta_cols = [c for c in df.columns if c in drop_exact or c.startswith(drop_prefixes)]\n",
    "df_work = df.drop(columns=meta_cols, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe3f358-e2b0-4abd-9462-ec46b5d5cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_25828\\2637413743.py:54: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  candidates = [c for c in pd.unique(resolved + auto_per90) if c in num_cols]\n"
     ]
    }
   ],
   "source": [
    "# Domänbasierte Startmenge\n",
    "# Fokus: per-90 & Progression/Creation & Defensiv-Kern\n",
    "preferred_features = [\n",
    "    # per-90 offensive\n",
    "    'Gls/90','Ast/90','G+A/90','G-PK/90','xG/90','xAG/90','xG+xAG/90','npxG/90','npxG+xAG/90',\n",
    "    'Sh/90','SoT/90',\n",
    "    # creation\n",
    "    'SCA90','GCA90','KP','PPA','1/3','CrsPA','PrgP',\n",
    "    # progression & receiving\n",
    "    'PrgC','PrgR',\n",
    "    # defensive kern\n",
    "    'Tkl','TklW','Int','Blocks','Clr','Won%','Aerials Won','Aerials Lost',\n",
    "    # ballbesitz / carries / take-ons\n",
    "    'Touches','Att 3rd','Mid 3rd','Att Pen','Carries','Succ%','Mis','Dis',\n",
    "    # effizienz\n",
    "    'G/Sh','G/SoT','npxG/Sh',\n",
    "]\n",
    "\n",
    "# Manche Datensätze nutzen leicht andere Schreibweisen (z.B. Aerial Duels Won, Aerials Won)\n",
    "aliases = {\n",
    "    'Aerials Won': ['Aerial Duels Won','Won (Aerials)','Won'],\n",
    "    'Aerials Lost': ['Lost (Aerials)','Lost'],\n",
    "    'Won%': ['Aerials Won%','Won% (Aerials)'],\n",
    "    'Touches': ['Touches (Total)'],\n",
    "    'Att 3rd': ['Touches (Att 3rd)'],\n",
    "    'Mid 3rd': ['Touches (Mid 3rd)'],\n",
    "    'Att Pen': ['Touches (Att Pen)'],\n",
    "}\n",
    "\n",
    "# Hilfsfunktion: Feature oder seine Aliase, falls vorhanden\n",
    "def resolve_feature(name, df_cols):\n",
    "    if name in df_cols:\n",
    "        return name\n",
    "    for k, alist in aliases.items():\n",
    "        if name == k:\n",
    "            for alt in alist:\n",
    "                if alt in df_cols:\n",
    "                    return alt\n",
    "    return None\n",
    "\n",
    "resolved = []\n",
    "for f in preferred_features:\n",
    "    got = resolve_feature(f, df_work.columns)\n",
    "    if got is not None:\n",
    "        resolved.append(got)\n",
    "\n",
    "# Zusätzlich ALLE numerischen /90-Spalten automatisch mitnehmen (z. B. SCA90, GCA90 etc.)\n",
    "auto_per90 = [c for c in df_work.columns if isinstance(c, str) and (('/90' in c) or c.endswith('90'))]\n",
    "\n",
    "# Numerische Spalten filtern\n",
    "num_cols = df_work.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Kandidaten = (domänenbasiert gefundene + auto_per90) ∩ numerische Spalten\n",
    "candidates = [c for c in pd.unique(resolved + auto_per90) if c in num_cols]\n",
    "\n",
    "# Fallback: Wenn durch die Heuristik zu wenig da ist, nimm einfach ALLE numerischen\n",
    "if len(candidates) < 8:\n",
    "    candidates = num_cols.copy()\n",
    "\n",
    "X0 = df_work[candidates].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a042fdfe-23e4-4c33-abff-e68e9ddad853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenqualität: Vollständigkeit & simple Imputation\n",
    "# Vollständigkeit berechnen\n",
    "completeness = X0.notna().mean()\n",
    "\n",
    "# Spalten mit zu vielen NaNs entfernen\n",
    "keep_cols = completeness[completeness >= COMPLETENESS_MIN].index.tolist()\n",
    "X1 = X0[keep_cols].copy()\n",
    "\n",
    "# Für verbleibende NaNs median\n",
    "X1 = X1.fillna(X1.median(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1af3ef5-3032-497d-93e6-fa64069fef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianz\n",
    "variances = X1.var(numeric_only=True)\n",
    "keep_cols_var = variances[variances > 0.0].index.tolist()\n",
    "X2 = X1[keep_cols_var].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812514d1-ce78-4ff1-b556-1db002ffd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelation\n",
    "corr = X2.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "\n",
    "# Wenn zwei Features redundant sind, behalten mit:\n",
    "# 1) höherer Vollständigkeit, sonst 2) höherer Varianz\n",
    "to_drop = set()\n",
    "for col in upper.columns:\n",
    "    high = upper.index[upper[col] > CORR_MAX].tolist()\n",
    "    for h in high:\n",
    "        c1, c2 = col, h\n",
    "        # Priorität: Vollständigkeit\n",
    "        c1_comp = completeness.get(c1, 0)\n",
    "        c2_comp = completeness.get(c2, 0)\n",
    "        if c1_comp != c2_comp:\n",
    "            drop = c1 if c1_comp < c2_comp else c2\n",
    "        else:\n",
    "            # Tie-breaker: Varianz\n",
    "            c1_var = variances.get(c1, 0)\n",
    "            c2_var = variances.get(c2, 0)\n",
    "            drop = c1 if c1_var < c2_var else c2\n",
    "        to_drop.add(drop)\n",
    "\n",
    "X3 = X2.drop(columns=list(to_drop), errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0534954f-4f9a-417b-890c-ee29e69c9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling für Clsutering\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X3), columns=X3.columns, index=X3.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c68ce21-3872-48af-b18e-6cb0742e1ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Feature-Auswahl Bericht --\n",
      "1) Start-Kandidaten: 18 Spalten\n",
      "2) Nach Vollständigkeit (≥ 70%): 15 Spalten\n",
      "3) Nach Varianzfilter: 15 Spalten\n",
      "4) Nach Korrelationsfilter (>|0.9|): 14 Spalten\n",
      "\n",
      "Gewählte Features (für Clustering):\n",
      " - SCA90\n",
      " - GCA90\n",
      " - KP\n",
      " - PPA\n",
      " - 1/3\n",
      " - CrsPA\n",
      " - PrgP\n",
      " - Int\n",
      " - Clr\n",
      " - Touches\n",
      " - TeamSuccess+/-90\n",
      " - TeamSuccess(xG)xG+/-90\n",
      " - StandardSh/90\n",
      " - StandardSoT/90\n"
     ]
    }
   ],
   "source": [
    "# Reporting\n",
    "print(\"-- Feature-Auswahl Bericht --\")\n",
    "print(f\"1) Start-Kandidaten: {len(candidates)} Spalten\")\n",
    "print(f\"2) Nach Vollständigkeit (≥ {int(COMPLETENESS_MIN*100)}%): {X1.shape[1]} Spalten\")\n",
    "print(f\"3) Nach Varianzfilter: {X2.shape[1]} Spalten\")\n",
    "print(f\"4) Nach Korrelationsfilter (>|{CORR_MAX}|): {X3.shape[1]} Spalten\")\n",
    "print(\"\\nGewählte Features (für Clustering):\")\n",
    "for c in X3.columns:\n",
    "    print(\" -\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ccc52fd-62af-453a-8ae7-f714194db0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neu erzeugte per90-Spalten: keine (evtl. existieren sie schon)\n",
      "CSV-Datei gespeichert unter: C:\\Users\\valen\\OneDrive\\Dokumente\\01_Studium\\9\\Probabilistic ML\\Local\\player_stats_with_per90.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Per-90-Features erzeugen + als CSV speichern\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ---- Einstellungen ----\n",
    "# Zählmetriken (Totals), NICHT bereits per 90 und keine Prozentwerte\n",
    "absolute_features = [\"KP\", \"PPA\", \"1/3\", \"CrsPA\", \"PrgP\", \"Int\", \"Clr\", \"Touches\"]\n",
    "\n",
    "minutes_col = \"PlayingTimeMin\"\n",
    "output_filename = \"player_stats_with_per90.csv\"\n",
    "\n",
    "# ---- Checks ----\n",
    "if minutes_col not in df.columns:\n",
    "    raise KeyError(f\"Die Minuten-Spalte '{minutes_col}' ist in df nicht vorhanden.\")\n",
    "\n",
    "missing = [c for c in absolute_features if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"Hinweis: Diese Features fehlen und werden übersprungen:\", missing)\n",
    "\n",
    "# Nur vorhandene Kandidaten\n",
    "candidates = [c for c in absolute_features if c in df.columns]\n",
    "\n",
    "# Bereits pro-90 benannte Spalten (verhindert Doppel-Umrechnung)\n",
    "already_per90_pattern = re.compile(r\"(/90$|_per90$|90$)\", re.IGNORECASE)\n",
    "\n",
    "created_cols = []\n",
    "minutes_safe = df[minutes_col].replace(0, np.nan)  # sicher gegen Division durch 0\n",
    "\n",
    "for feat in candidates:\n",
    "    # Feature überspringen, falls es bereits eine per-90-Version gibt\n",
    "    if already_per90_pattern.search(feat):\n",
    "        continue\n",
    "    new_col = f\"{feat}_per90\"\n",
    "    # Wenn es die Zielspalte schon gibt, überschreiben wir sie NICHT (Nachvollziehbarkeit)\n",
    "    if new_col in df.columns:\n",
    "        continue\n",
    "    df[new_col] = (df[feat] / minutes_safe) * 90\n",
    "    created_cols.append(new_col)\n",
    "\n",
    "print(\"Neu erzeugte per90-Spalten:\", created_cols if created_cols else \"keine (evtl. existieren sie schon)\")\n",
    "\n",
    "# ---- CSV speichern ----\n",
    "base_dir = os.path.dirname(DATA_PATH) if 'DATA_PATH' in globals() else os.getcwd()\n",
    "output_path = os.path.join(base_dir, output_filename)\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"CSV-Datei gespeichert unter: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabab3c-0efa-4e5a-8682-370adb14026f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0408e-a687-4c47-a196-a9bbb93bfc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
