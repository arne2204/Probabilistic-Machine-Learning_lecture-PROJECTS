{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8f5d6f-076c-447d-bef2-80819d48ef73",
   "metadata": {},
   "source": [
    "# Probabilistic Machine Learning - Project Report\n",
    "\n",
    "## Fraud detection\n",
    "\n",
    "- **Course:** Probabilistic Machine Learning (SoSe 2025)\n",
    "- **Lecturer:** Alvaro Diaz-Ruelas\n",
    "- **Students Names:**  khalid Sabih, abdellah charki\n",
    "- **GitHub Usernames:**  @khalidsabih / @abdellahcharki\n",
    "- **Date:**  05/07/2025\n",
    "- **PROJECT-ID:** 26-1CASKXX  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5953b-fa07-4df8-9ede-ff33b5867093",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554a04d-57da-404b-88b3-7caa294ac841",
   "metadata": {},
   "source": [
    "## 1.1 Motivation\n",
    "Fraud detection has become an increasingly critical task in financial systems and digital transactions, where even a small number of fraudulent activities can result in significant financial losses and erode trust in institutions. The complexity of detecting fraud arises from its rarity and the constantly evolving tactics used by fraudsters to conceal illicit activities within massive volumes of legitimate transactions. As organizations handle millions of financial operations daily, distinguishing fraudulent patterns from normal behavior is both technically challenging and essential for operational security and customer trust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f433af-293f-4cf5-99d5-1e5ed705ff88",
   "metadata": {},
   "source": [
    "## 1.2 Dataset\n",
    "The dataset used in this project, named Fraud.csv, consists of approximately 6 million synthetic financial transactions, created to reflect realistic banking operations while protecting privacy. Each transaction record contains several attributes that describe its details, including both numerical and categorical features. The primary challenge posed by this dataset is the severe class imbalance, as fraudulent transactions account for fewer than 0.2% of all records, making fraud detection a complex and highly imbalanced classification problem.\n",
    "\n",
    "The dataset includes the following columns:\n",
    "\n",
    "- step: The hour of the simulation.\n",
    "- type: The type of transaction, such as PAYMENT, TRANSFER, CASH_OUT, DEBIT, or CASH_IN.\n",
    "- amount: The amount of money involved in the transaction.\n",
    "- nameOrig: An anonymized identifier for the originator’s account.\n",
    "- oldbalanceOrg: The account balance of the originator before the transaction.\n",
    "- newbalanceOrig: The account balance of the originator after the transaction.\n",
    "- nameDest: An anonymized identifier for the recipient’s account.\n",
    "- oldbalanceDest: The account balance of the recipient before the transaction.\n",
    "- newbalanceDest: The account balance of the recipient after the transaction.\n",
    "- isFraud: A binary label indicating whether the transaction was fraudulent (1) or not (0).\n",
    "- isFlaggedFraud: A binary flag indicating whether the transaction was flagged as suspicious by internal business rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2ab2f-0a13-4dfb-b40f-fdb23e6703a4",
   "metadata": {},
   "source": [
    "## 1.3 Hypothesis\n",
    "- Fraudulent transactions are more likely to occur in specific transaction types, particularly TRANSFER and CASH_OUT, compared to other types such as PAYMENT or CASH_IN.\n",
    "- Fraudulent transactions tend to involve higher transaction amounts than legitimate transactions.\n",
    "- Fraudulent transactions often result in the destination account balance dropping to zero, suggesting immediate withdrawal or transfer of illicit funds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664968ed-44cf-4df3-971f-99fa14324f98",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Exploration\n",
    "## 2.1. Data Loading\n",
    "We use a synthetic fraud detection dataset for training and evaluating fraud detection models.\n",
    "\n",
    "\n",
    "[Fraud Detection Dataset – Kaggle](https://www.kaggle.com/datasets/ashishkumarjayswal/froud-detection-dataset)\n",
    "\n",
    "\n",
    "Our analysis begins with loading the dataset Fraud.csv, which is stored in the  `data/` folder of our project repository. We use the pandas library in Python to handle the file, as it efficiently manages large datasets and provides useful tools for data exploration.\n",
    "\n",
    "**Snapshot of Original Dataset (Before Preprocessing)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed1ad35",
   "metadata": {},
   "source": [
    "| step | type      | amount   | nameOrig       | oldbalanceOrg | newbalanceOrig | nameDest     | oldbalanceDest | newbalanceDest | isFraud | isFlaggedFraud |\n",
    "|------|-----------|----------|----------------|---------------|----------------|--------------|----------------|----------------|---------|----------------|\n",
    "| 1    | PAYMENT   | 9839.64  | C1231006815    | 170136.0      | 160296.36      | M1979787155  | 0.0            | 0.0            | 0       | 0              |\n",
    "| 1    | PAYMENT   | 1864.28  | C1666544295    | 21249.0       | 19384.72       | M2044282225  | 0.0            | 0.0            | 0       | 0              |\n",
    "| 1    | TRANSFER  | 181.00   | C1305486145    | 181.0         | 0.00           | C553264065   | 0.0            | 0.0            | 1       | 0              |\n",
    "| 1    | CASH_OUT  | 181.00   | C840083671     | 181.0         | 0.00           | C38997010    | 21182.0        | 0.0            | 1       | 0              |\n",
    "| 1    | PAYMENT   | 11668.14 | C2048537720    | 41554.0       | 29885.86       | M1230701703  | 0.0            | 0.0            | 0       | 0              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4076fa",
   "metadata": {},
   "source": [
    "## 2.2. Data Exploration\n",
    "After successfully loading the dataset, we performed a detailed exploratory data analysis to better understand its structure and the nature of fraudulent transactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016dd21",
   "metadata": {},
   "source": [
    "### 2.2.1 Class Distribution\n",
    "A critical first step was to examine the distribution of our target variable, isFraud. As shown in Figure  (Class Distribution), fraudulent transactions are extremely rare, accounting for only about 0.13% of all transactions. In absolute terms, there are 8,213 fraudulent transactions out of a total of 6,354,620 transactions, which is consistent with the class distribution reported as follows:\n",
    "- Non-fraudulent (0): 6,354,407 transactions (99.87%)\n",
    "- Fraudulent (1): 8,213 transactions (0.13%)\n",
    "\n",
    "\n",
    "![Class Distribution](/results/class_distribution.png)\n",
    "\n",
    "This significant class imbalance underscores the challenges associated with fraud detection, where traditional metrics like overall accuracy would be misleading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa72ff",
   "metadata": {},
   "source": [
    "### 2.2.2 Fraud Rate by Transaction Type\n",
    "We then analyzed how fraud is distributed across different transaction types. The dataset includes various transaction categories such as PAYMENT, TRANSFER, CASH_OUT, DEBIT, and CASH_IN. Our analysis revealed that fraud is concentrated almost exclusively in the TRANSFER and CASH_OUT transaction types.\n",
    "Figure (Fraud Rate by Transaction Type) illustrates that:\n",
    "\n",
    "- TRANSFER transactions account for approximately 80.69% of fraudulent activity.\n",
    "\n",
    "- CASH_OUT transactions account for about 19.31% of fraud.\n",
    "\n",
    "- Other transaction types show virtually no fraud.\n",
    "\n",
    "![Fraud Rate by Transaction Type](./results/fraud_rate_by_transaction.png)\n",
    "\n",
    "These findings highlight the importance of transaction type as a strong predictor of fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ebfe4",
   "metadata": {},
   "source": [
    "### 2.2.3 Transaction Type vs. Fraud Count\n",
    "To visualize how fraud and non-fraud transactions are distributed across different transaction types, we plotted a count graph, shown in Figure 3 (Transaction Type vs. Fraud). The chart confirms that while PAYMENT, CASH_IN, and DEBIT transactions are numerous, they rarely involve fraud. By contrast, TRANSFER and CASH_OUT transactions, although less frequent overall, carry a much higher proportion of fraudulent cases relative to their volume.\n",
    "\n",
    "This information is critical for model development, suggesting that the transaction type should be included as a categorical feature in any predictive modeling approach.\n",
    "\n",
    "\n",
    "![Transaction Type vs. Fraud Count](./results/Transaction_Type_vs_Fraud.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f7d03",
   "metadata": {},
   "source": [
    "### 2.2.4 Correlation Analysis\n",
    "To further investigate relationships between variables, we computed and visualized a correlation heatmap, presented in Figure (Correlation Heatmap). \n",
    "The heatmap provides insights into how features relate to each other and to the target variable `isFraud`.\n",
    "\n",
    "The strongest positive correlations with isFraud were observed for:\n",
    "\n",
    "- `amount` (correlation coefficient ≈ 0.0767)\n",
    "- `type_TRANSFER` (≈ 0.0539)\n",
    "- `isFlaggedFraud` (≈ 0.0441)\n",
    "\n",
    "Meanwhile, features such as type_PAYMENT show a slight negative correlation with fraud. Although these correlation values are generally low, they point to certain trends that may help distinguish fraudulent transactions.\n",
    "\n",
    "![Correlation Analysis](results/heatmap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08255acb",
   "metadata": {},
   "source": [
    "### 2.2.5 Insights from Data Exploration\n",
    "From this exploratory phase, we can conclude several important patterns:\n",
    "\n",
    "- The dataset is highly imbalanced, with fraud representing less than 0.2% of transactions.\n",
    "- Fraud occurs almost exclusively in TRANSFER and CASH_OUT transactions.\n",
    "- Fraudulent transactions often involve larger amounts, supporting the hypothesis that transaction value is a key indicator of potential fraud.\n",
    "- Correlation analysis, while showing modest relationships, suggests that transaction type and amount are among the most informative features for predicting fraud.\n",
    "\n",
    "These findings inform the direction of our feature engineering and modeling strategies. In particular, they emphasize the need to account for class imbalance and to focus on transaction types and amounts when building fraud detection models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe0c5a-f0f4-4088-8f7a-23ba05088f25",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "Before developing any models, we performed several preprocessing steps to prepare the dataset for analysis. These steps ensured that the data was clean, consistent, and suitable for machine learning algorithms.\n",
    "\n",
    "- **Verified missing values:**  Checked all columns and confirmed there was no missing data.\n",
    "- **Data type checks:** Verified that numeric columns remained as floats or integers, and that new one-hot encoded columns were stored as boolean values.\n",
    "- **remove unneeded column:**  Removed the columns  `nameOrig` and `nameDest`.\n",
    "- **Column transfer:**  Transformed the type column (categorical) into multiple binary columns such as `type_PAYMENT`, `type_TRANSFER`, etc. Each new column indicates whether the transaction belongs to that type (True/False).\n",
    "\n",
    " **Snapshot of Transformed Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e69879",
   "metadata": {},
   "source": [
    "\n",
    "| step | amount   | oldbalanceOrg | newbalanceOrig | oldbalanceDest | newbalanceDest | isFraud | isFlaggedFraud | type_CASH_OUT | type_DEBIT | type_PAYMENT | type_TRANSFER |\n",
    "|------|----------|---------------|----------------|----------------|----------------|---------|----------------|---------------|------------|--------------|---------------|\n",
    "| 1    | 9839.64  | 170136.00     | 160296.36      | 0.00           | 0.00           | 0       | 0              | False         | False      | True         | False         |\n",
    "| 1    | 1864.28  | 21249.00      | 19384.72       | 0.00           | 0.00           | 0       | 0              | False         | False      | True         | False         |\n",
    "| 1    | 181.00   | 181.00        | 0.00           | 0.00           | 0.00           | 1       | 0              | False         | False      | False        | True          |\n",
    "| 1    | 181.00   | 181.00        | 0.00           | 21182.00       | 0.00           | 1       | 0              | True          | False      | False        | False         |\n",
    "| 1    | 11668.14 | 41554.00      | 29885.86       | 0.00           | 0.00           | 0       | 0              | False         | False      | True         | False         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38639b92-f5da-4a1a-b44a-ccca9ce1b921",
   "metadata": {},
   "source": [
    "# 4. Modeling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4e990",
   "metadata": {},
   "source": [
    "In this project, we applied several probabilistic and statistical classification models to detect fraudulent transactions. The selection was guided by the need to handle a highly imbalanced dataset, maintain interpretability, and explore both discriminative "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6940d74",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression (Frequentist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fa1f0",
   "metadata": {},
   "source": [
    "A baseline discriminative model that estimates the probability of fraud using the logistic function:\n",
    "![ddd](results/eq1.png)\n",
    "\n",
    "The parameters β are estimated by maximizing the likelihood (equivalently minimizing the log-loss). Logistic regression is interpretable and provides calibrated probability outputs, making it suitable for fraud detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971409cf",
   "metadata": {},
   "source": [
    "### 4.2 Bayesian Logistic Regression\n",
    "Extends logistic regression by placing a prior over the parameters β (e.g., Gaussian prior) and inferring a posterior distribution:\n",
    "![ddd](results/eq2.png)\n",
    "\n",
    "This allows quantifying parameter uncertainty and producing posterior predictive distributions, which can be valuable in decision-making under uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12079d7e",
   "metadata": {},
   "source": [
    "### 4.3 Naive Bayes\n",
    "A generative model assuming conditional independence between features given the class label. Using Bayes’ theorem:\n",
    "![ddd](results/eq3.png)\n",
    "\n",
    "While the independence assumption is often violated, Naive Bayes is computationally efficient and can perform well when features are weakly correlated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff17cf",
   "metadata": {},
   "source": [
    "### 4.4 Weighted Logistic Regression\n",
    "A modification of the logistic regression model to address class imbalance by setting `class_weight='balanced'`. The weighted loss is:\n",
    "![ddd](results/eq4.png)\n",
    "\n",
    "where W_y_i is inversely proportional to the class frequency. This ensures the minority fraud class has greater influence on the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f067a3",
   "metadata": {},
   "source": [
    "### 4.5 Linear Discriminant Analysis (LDA)\n",
    "A Gaussian Discriminant Analysis method that assumes each class follows a Gaussian distribution with the same covariance matrix Σ, leading to linear decision boundaries. The discriminant function is:\n",
    "\n",
    "![ddd](results/eq5.png)\n",
    "\n",
    "We used balanced priors  ( 𝜋0 = 𝜋1 = 0.5 ) to counter the strong class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33371ed8",
   "metadata": {},
   "source": [
    "### 4.6 Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "Similar to LDA, but each class has its own covariance matrix Σ𝑘, allowing quadratic decision boundaries:\n",
    "\n",
    "![ddd](results/eq6.png)\n",
    "\n",
    "We also used balanced priors to avoid bias toward the majority class. A small regularization term was applied to improve numerical stability in the presence of multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd02fa-90ee-4d3f-aa6f-83ebc6d70f12",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation\n",
    "- Model evaluation (metrics, plots, performance)\n",
    "- Cross-validation or uncertainty quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef3ab2",
   "metadata": {},
   "source": [
    "### 5.1 Data Preparation for Modeling\n",
    "All models used the same preprocessed dataset to ensure fair comparison. Preprocessing steps included:\n",
    "- **One-Hot Encoding** of the categorical variable `type`.\n",
    "- **Removal** of identifier columns `nameOrig` and `nameDest`.\n",
    "- **Standardization** of numerical variables for models sensitive to feature scale (LDA, QDA, Logistic Regression).\n",
    "- **Train/Test Split**: 80% training, 20% testing, stratified by the target variable to maintain the fraud/non-fraud proportion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29d4a0",
   "metadata": {},
   "source": [
    "### 5.2 Training Procedures\n",
    "#### 5.2.1 Frequentist Logistic Regression\n",
    "\n",
    "The frequentist logistic regression model was trained using scikit-learn’s `LogisticRegression` with `max_iter=1000`.  \n",
    "This model estimates the probability of a transaction being fraudulent using a linear decision boundary in the feature space, optimized via maximum likelihood estimation.\n",
    "\n",
    "- **ROC AUC**: 0.9874  \n",
    "- **Accuracy**: 0.96  \n",
    "- **Classification Report (Fraud class)**:  \n",
    "  - Precision: 0.03  \n",
    "  - Recall: 0.92  \n",
    "  - F1-score: 0.06  \n",
    "\n",
    "**Interpretation:**  \n",
    "The model achieves a very high recall for fraudulent transactions, detecting the majority of fraud cases.  \n",
    "However, the low precision indicates a high number of false positives, which may lead to unnecessary manual reviews.  \n",
    "This trade-off can be acceptable in high-stakes fraud detection, where missing fraud is costlier than investigating false alerts.\n",
    "\n",
    "**Performance Curves:**  \n",
    "![ROC Curve - Logistic Regression](results/output1.png)   ![Precision-Recall Curve - Logistic Regression](results/output2.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2cbe0e",
   "metadata": {},
   "source": [
    "#### 5.2.2 Naive Bayes\n",
    "\n",
    "The Gaussian Naive Bayes model was trained using scikit-learn’s `GaussianNB`.  \n",
    "It assumes that the features are conditionally independent given the class label and that each feature follows a Gaussian distribution within each class.\n",
    "\n",
    "- **ROC AUC**: 0.8075  \n",
    "- **Accuracy**: 0.99  \n",
    "\n",
    "- **Classification Report (Fraud class)**:  \n",
    "  - Precision: 0.03  \n",
    "  - Recall: 0.16  \n",
    "  - F1-score: 0.06  \n",
    "  \n",
    "**Interpretation:**  \n",
    "The model achieves high accuracy due to the overwhelming number of non-fraud cases but performs poorly in recall and precision for fraud detection.  \n",
    "Its strong independence assumption does not hold for this dataset, which limits its ability to detect fraudulent transactions effectively.\n",
    "\n",
    "**Performance Curves:**  \n",
    "![ROC Curve - Naive Bayes](results/output3.png)   ![Precision-Recall Curve - Naive Bayes](results/output4.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb2a1ab",
   "metadata": {},
   "source": [
    "#### 5.2.3 Bayesian Logistic Regression\n",
    "\n",
    "The Bayesian logistic regression model was implemented using a probabilistic programming framework (e.g., PyMC) with Gaussian priors placed over the model coefficients.  \n",
    "Inference was performed via Markov Chain Monte Carlo (MCMC) sampling, allowing estimation of full posterior distributions for the parameters and predictive probabilities.\n",
    "\n",
    "- **ROC AUC**: 0.9668  \n",
    "- **Accuracy**: 0.99  \n",
    "\n",
    "- **Classification Report (Fraud class)**:  \n",
    "  - Precision: 1.00  \n",
    "  - Recall: 0.07  \n",
    "  - F1-score: 0.14  \n",
    "  \n",
    "**Interpretation:**  \n",
    "The model achieves perfect precision for the fraud class, meaning that every predicted fraud case is truly fraudulent.  \n",
    "However, this comes at the cost of very low recall, missing the majority of fraud cases.  \n",
    "The Bayesian approach provides uncertainty estimates for predictions, which can be leveraged in operational settings to set more informed thresholds.\n",
    "\n",
    "**Performance Plot (Posterior Distributions):**  \n",
    "![Posterior Distributions - Bayesian Logistic Regression](results/output5.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a67e9b",
   "metadata": {},
   "source": [
    "#### 5.2.4 Weighted Logistic Regression\n",
    "\n",
    "The weighted logistic regression model was trained using scikit-learn’s `LogisticRegression` with the parameter `class_weight='balanced'`.  \n",
    "This approach adjusts the loss function to give more weight to the minority fraud class, compensating for the severe class imbalance.\n",
    "\n",
    "- **ROC AUC**: 0.9874  \n",
    "- **Accuracy**: 0.96  \n",
    "\n",
    "- **Classification Report (Fraud class)**:  \n",
    "  - Precision: 0.03  \n",
    "  - Recall: 0.92  \n",
    "  - F1-score: 0.06  \n",
    "\n",
    "  **Interpretation:**  \n",
    "By rebalancing class weights, the model maintains very high recall for fraud detection, capturing the vast majority of fraudulent transactions.  \n",
    "However, precision remains low, resulting in a large number of false positives.  \n",
    "This trade-off is often acceptable in fraud detection, where missing a fraud case is costlier than investigating a false alert.\n",
    "\n",
    "**Performance Curves:**  \n",
    "![ROC Curve - Weighted Logistic Regression](results/output1.png)   ![Precision-Recall Curve - Weighted Logistic Regression](results/output2.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2b7cb",
   "metadata": {},
   "source": [
    "#### 5.2.5 Linear Discriminant Analysis (LDA)\n",
    "\n",
    "The LDA model was trained using scikit-learn’s `LinearDiscriminantAnalysis` with balanced priors (`priors=[0.5, 0.5]`).  \n",
    "LDA assumes that each class follows a Gaussian distribution with the same covariance matrix, resulting in linear decision boundaries.\n",
    "\n",
    "- **ROC AUC**: 0.9455  \n",
    "- **Accuracy**: 0.9991  \n",
    "\n",
    "- **Classification Report (Fraud class)**:  \n",
    "  - Precision: 0.7698  \n",
    "  - Recall: 0.3786  \n",
    "  - F1-score: 0.5075  \n",
    "\n",
    "**Interpretation:**  \n",
    "LDA achieves very high precision for fraud detection, meaning most flagged cases are truly fraudulent.  \n",
    "However, recall is moderate, meaning some fraud cases are missed.  \n",
    "This makes LDA more suited for scenarios where minimizing false positives is a priority.\n",
    "\n",
    "**Performance Curves:**  \n",
    "![ROC — LDA (Balanced Priors)](results/photo_2025-08-11_22-04-15_3.jpg)   ![Precision–Recall — LDA (Balanced Priors)](results/photo_2025-08-11_22-04-15_4.jpg)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69745e5",
   "metadata": {},
   "source": [
    "\n",
    "#### 5.2.6 Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "The QDA model was trained using scikit-learn’s `QuadraticDiscriminantAnalysis` with balanced priors (`priors=[0.5, 0.5]`) and a small regularization parameter (`reg_param=1e-3`) to handle covariance singularities.  \n",
    "QDA allows each class to have its own covariance matrix, resulting in quadratic decision boundaries.\n",
    "\n",
    "- **ROC AUC**: 0.9790  \n",
    "- **Accuracy**: 0.6344  \n",
    "\n",
    "- **Classification Report (Fraud class)**:  \n",
    "  - Precision: 0.0035  \n",
    "  - Recall: 1.0000  \n",
    "  - F1-score: 0.0070  \n",
    "\n",
    "**Interpretation:**  \n",
    "QDA achieves perfect recall for fraud detection, capturing all fraudulent transactions.  \n",
    "However, the precision is extremely low, meaning nearly all flagged transactions are false positives.  \n",
    "This makes QDA impractical for deployment in production systems without additional filtering mechanisms.\n",
    "\n",
    "**Performance Curves:**  \n",
    "![ROC — QDA (Balanced Priors)](results/photo_2025-08-11_22-04-15.jpg)  \n",
    "![Precision–Recall — QDA (Balanced Priors)](results/photo_2.jpg)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd14725-ab42-4588-8f8e-c5935726c10d",
   "metadata": {},
   "source": [
    "## 6. Results\n",
    "\n",
    "### 6.1 Model Performance Summary\n",
    "\n",
    "| Model | ROC AUC | Accuracy | Precision (Fraud) | Recall (Fraud) | F1 (Fraud) |\n",
    "|-------|---------|----------|-------------------|----------------|------------|\n",
    "| Frequentist Logistic Regression | 0.9874 | 0.9600 | 0.03 | 0.92 | 0.06 |\n",
    "| Naive Bayes | 0.8075 | 0.9900 | 0.03 | 0.16 | 0.06 |\n",
    "| Bayesian Logistic Regression | 0.9668 | 0.9900 | 1.00 | 0.07 | 0.14 |\n",
    "| Weighted Logistic Regression | 0.9874 | 0.9600 | 0.03 | 0.92 | 0.06 |\n",
    "| LDA (Balanced Priors) | 0.9455 | 0.9991 | 0.7698 | 0.3786 | 0.5075 |\n",
    "| QDA (Balanced Priors) | 0.9790 | 0.6344 | 0.0035 | 1.0000 | 0.0070 |\n",
    "\n",
    "\n",
    "### 6.2 Observations from Performance Metrics\n",
    "- **Best Overall ROC AUC**: Frequentist Logistic Regression and Weighted Logistic Regression (0.9874), closely followed by QDA (0.9790).\n",
    "- **Best Precision**: Bayesian Logistic Regression (1.00) — but at the cost of very low recall.\n",
    "- **Best Recall**: QDA (1.0) — but with extremely low precision, making it impractical without additional filtering.\n",
    "- **Balanced Performance**: LDA offers a better trade-off between precision and recall compared to QDA, but with lower recall than Logistic Regression.\n",
    "- **Effect of Class Balancing**: Weighted Logistic Regression greatly improves recall over Bayesian Logistic Regression but keeps precision low.\n",
    "\n",
    "### 6.3 ROC and Precision–Recall Curve Analysis\n",
    "**ROC Curves**:\n",
    "- Logistic Regression models (Frequentist & Weighted) and QDA show curves close to the top-left corner, indicating strong classification performance.\n",
    "- LDA’s ROC curve is slightly lower, reflecting its more conservative detection strategy.\n",
    "\n",
    "**Precision–Recall Curves**:\n",
    "- Bayesian Logistic Regression maintains high precision at low recall.\n",
    "- Weighted Logistic Regression and Frequentist Logistic Regression achieve much higher recall but see a drop in precision.\n",
    "- QDA reaches full recall but with a near-zero precision plateau.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1f4eb-2312-4ef3-ac92-cf0a1d0eff7f",
   "metadata": {},
   "source": [
    "## 7. Discussion\n",
    "\n",
    "The experiments reveal the challenges of detecting fraudulent transactions in a **highly imbalanced dataset**, where the majority of cases are legitimate.  \n",
    "In such settings, overall accuracy is not a reliable indicator of model performance, as seen with Naive Bayes and LDA, which achieve very high accuracy but differ greatly in their ability to detect fraud.\n",
    "\n",
    "### 7.1 Trade-off Between Precision and Recall\n",
    "Fraud detection systems must balance **recall** (catching as many fraudulent cases as possible) and **precision** (minimizing false alarms).  \n",
    "- **High Recall Models**: Frequentist Logistic Regression, Weighted Logistic Regression, and QDA excel at detecting nearly all fraud cases, but QDA’s extreme false-positive rate makes it unsuitable without post-processing filters.  \n",
    "- **High Precision Models**: Bayesian Logistic Regression and LDA minimize false positives, which is beneficial for reducing investigation costs, but they miss many fraudulent cases due to lower recall.\n",
    "\n",
    "### 7.2 Impact of Class Imbalance Handling\n",
    "Introducing **class weighting** in Logistic Regression (Weighted LR) significantly improved fraud recall while keeping ROC AUC unchanged.  \n",
    "This suggests that weighting is a simple yet effective technique to counteract the bias toward the majority class in imbalanced datasets.\n",
    "\n",
    "### 7.3 Discriminant Analysis Models\n",
    "LDA and QDA provided insight into the distributional assumptions of the data:\n",
    "- **LDA** assumes shared covariance across classes, yielding stable decision boundaries and a balanced precision-recall trade-off.\n",
    "- **QDA** allows for separate covariances, leading to perfect recall but collapsing precision due to overfitting on rare fraud examples.\n",
    "\n",
    "### 7.4 Naive Bayes Limitations\n",
    "Naive Bayes underperformed in both precision and recall for the fraud class.  \n",
    "Its assumption of feature independence is likely violated in financial transaction data, leading to suboptimal classification boundaries.\n",
    "\n",
    "### 7.5 Model Selection for Deployment\n",
    "In a real-world fraud detection system:\n",
    "- **Weighted Logistic Regression** would be a strong candidate for deployment because it provides high recall (catching most fraud cases) while keeping the model interpretable and computationally efficient.\n",
    "- Bayesian Logistic Regression could be integrated as a **second-stage verification model** to filter out high-confidence fraud predictions, thus reducing false positives.\n",
    "- LDA could be used in conjunction with Logistic Regression in an **ensemble approach** to balance recall and precision.\n",
    "\n",
    "### 7.6 Practical Considerations\n",
    "- Models with high recall but low precision (like QDA) can cause operational inefficiencies due to the large number of false positives.\n",
    "- Conversely, models with high precision but low recall risk missing costly fraudulent transactions.\n",
    "- In practice, the decision threshold can be tuned based on business requirements and resource constraints for fraud investigation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e00b16-7ecf-49ac-9564-3cccf20f0ea0",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This project compared several probabilistic and discriminative models for fraud detection on a highly imbalanced dataset.  \n",
    "Weighted Logistic Regression provided the best trade-off, maintaining very high recall while remaining interpretable.  \n",
    "Bayesian Logistic Regression achieved perfect precision but low recall, making it better suited as a second-stage filter.  \n",
    "LDA offered high precision with moderate recall, while QDA achieved perfect recall but impractically low precision.  \n",
    "Naive Bayes underperformed due to its strong independence assumptions.\n",
    "\n",
    "Class weighting proved effective in improving fraud detection recall, confirming its value in imbalanced classification problems.  \n",
    "Future work could explore ensemble methods, cost-sensitive learning, and threshold tuning to further optimize performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe95a8-b421-42b9-925c-ed2c17e73169",
   "metadata": {},
   "source": [
    "## 9. References\n",
    "\n",
    "1. Dataset - [https://www.kaggle.com/datasets/ashishkumarjayswal/froud-detection-dataset](https://www.kaggle.com/datasets/ashishkumarjayswal/froud-detection-dataset)\n",
    "2. Probabilistic Machine Learning – Lecture Notes. Dr. Álvaro Díaz Ruelas, Leipzig University, 2025.  \n",
    "3. scikit-learn Documentation — [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)  \n",
    "4. PyMC Documentation — [https://www.pymc.io/](https://www.pymc.io/)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
