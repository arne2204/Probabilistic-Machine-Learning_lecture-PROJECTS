{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:40.957126Z",
     "start_time": "2025-06-30T07:57:38.745415Z"
    }
   },
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:40.961447Z",
     "start_time": "2025-06-30T07:57:40.959744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_CONFIGS = {\n",
    "    \"lightweight\": \"all-MiniLM-L6-v2\",      # 22M params, 384d\n",
    "    \"performance\": \"BAAI/bge-large-en-v1.5\"  # 335M params, 1024d\n",
    "}"
   ],
   "id": "9f30adba0edf750f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:41.038101Z",
     "start_time": "2025-06-30T07:57:41.036405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_device(device: str = \"auto\") -> str:\n",
    "    \"\"\"Determine optimal device for computation.\"\"\"\n",
    "    if device == \"auto\":\n",
    "        if torch.cuda.is_available():\n",
    "            return \"cuda\"\n",
    "        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "            return \"mps\"  # Apple Silicon GPU\n",
    "        else:\n",
    "            return \"cpu\"\n",
    "    return device"
   ],
   "id": "5b68340c32038fdd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:41.094445Z",
     "start_time": "2025-06-30T07:57:41.092706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_model(model_tier: str = \"lightweight\", device: str = \"auto\") -> SentenceTransformer:\n",
    "    \"\"\"Load and return the sentence transformer model.\"\"\"\n",
    "    device = get_device(device)\n",
    "    model_name = MODEL_CONFIGS[model_tier]\n",
    "\n",
    "    print(f\"Loading {model_name} on {device}...\")\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    print(f\"Model loaded. Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "    return model"
   ],
   "id": "ed28fdca29802673",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:41.610954Z",
     "start_time": "2025-06-30T07:57:41.608926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_json_data(json_path: str) -> List[Dict]:\n",
    "    \"\"\"Load and validate JSON token data.\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract tokens if nested in structure\n",
    "    tokens = data['tokens'] if 'tokens' in data else data\n",
    "    print(f\"Loaded {len(tokens)} tokens from {json_path}\")\n",
    "\n",
    "    return tokens"
   ],
   "id": "a15ff5b31e2aa30a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T08:43:53.019912Z",
     "start_time": "2025-06-30T08:43:53.014283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_label_features(tokens: List[Dict]) -> Tuple[np.ndarray, List[str], Dict]:\n",
    "    \"\"\"\n",
    "    Extract and encode label features from tokens.\n",
    "\n",
    "    Returns:\n",
    "        label_features: Standardized feature matrix\n",
    "        feature_names: Names of features\n",
    "        encoders: Dict of label encoders for later use\n",
    "    \"\"\"\n",
    "    # Collect all label types and values\n",
    "    all_labels = {}\n",
    "    for token in tokens:\n",
    "        for label_type, label_info in token['labels'].items():\n",
    "            value = label_info['value']\n",
    "            if label_type not in all_labels:\n",
    "                all_labels[label_type] = set()\n",
    "\n",
    "            # Only collect non-null values for encoding\n",
    "            if value != 'null' and value is not None:\n",
    "                all_labels[label_type].add(value)\n",
    "    # for token in tokens:\n",
    "    #     for label_type, label_info in token['labels'].items():\n",
    "    #         if label_type not in all_labels:\n",
    "    #             all_labels[label_type] = set()\n",
    "    #         all_labels[label_type].add(label_info['value'])\n",
    "\n",
    "    # Create label encoders for categorical variables\n",
    "    label_encoders = {}\n",
    "    for label_type, values in all_labels.items():\n",
    "        if 'null' in values or len(values) > 10:  # Categorical encoding\n",
    "            label_encoders[label_type] = LabelEncoder()\n",
    "            label_encoders[label_type].fit(list(values))\n",
    "\n",
    "    # Extract features for each token\n",
    "    label_data = []\n",
    "    for token in tokens:\n",
    "        token_features = []\n",
    "        for label_type, label_info in token['labels'].items():\n",
    "            value = label_info['value']\n",
    "            confidence = label_info['confidence']\n",
    "\n",
    "            # Handle null values properly\n",
    "            if value == 'null' or value is None:\n",
    "                # For null values: feature = 0.0, confidence = 0.0\n",
    "                token_features.extend([0.0, 0.0])\n",
    "\n",
    "            elif label_type in label_encoders:\n",
    "                # Categorical: encode and weight by confidence\n",
    "                try:\n",
    "                    encoded_val = label_encoders[label_type].transform([value])[0]\n",
    "                    token_features.extend([encoded_val * confidence, confidence])\n",
    "                except ValueError:\n",
    "                    # Unknown category (shouldn't happen but safety)\n",
    "                    token_features.extend([0.0, 0.0])\n",
    "\n",
    "            else:\n",
    "                # Numerical values\n",
    "                try:\n",
    "                    num_val = float(value)\n",
    "                    token_features.extend([num_val * confidence, confidence])\n",
    "                except (ValueError, TypeError):\n",
    "                    # Non-numeric string that's not categorical\n",
    "                    hash_val = hash(str(value)) % 1000\n",
    "                    token_features.extend([hash_val * confidence, confidence])\n",
    "\n",
    "        label_data.append(token_features)\n",
    "\n",
    "    # Convert to numpy and standardize\n",
    "    label_features = np.array(label_data)\n",
    "    zero_mask = (label_features == 0.0)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = label_features.copy()\n",
    "    if label_features.size > 0:\n",
    "        #label_features = scaler.fit_transform(label_features)\n",
    "        for col_idx in range(label_features.shape[1]):\n",
    "            column = label_features[:, col_idx]\n",
    "            zero_positions = zero_mask[:, col_idx]\n",
    "\n",
    "            # Only standardize if there are non-zero values\n",
    "            if not zero_positions.all():  # Not all zeros\n",
    "                non_zero_values = column[~zero_positions]\n",
    "                if len(non_zero_values) > 1:  # Need at least 2 values for std\n",
    "                    # Fit scaler on non-zero values\n",
    "                    scaler_col = StandardScaler()\n",
    "                    non_zero_scaled = scaler_col.fit_transform(non_zero_values.reshape(-1, 1)).flatten()\n",
    "\n",
    "                    # Put scaled values back, keep zeros as zeros\n",
    "                    scaled_features[~zero_positions, col_idx] = non_zero_scaled\n",
    "                    scaled_features[zero_positions, col_idx] = 0.0\n",
    "                else:\n",
    "                    # If only one non-zero value or all zeros, keep as is\n",
    "                    scaled_features[:, col_idx] = column\n",
    "        label_features = scaled_features\n",
    "\n",
    "    # Generate feature names\n",
    "    feature_names = []\n",
    "    for label_type in sorted(all_labels.keys()):\n",
    "        feature_names.extend([f\"{label_type}_value\", f\"{label_type}_confidence\"])\n",
    "\n",
    "    print(f\"Extracted {len(feature_names)} label features\")\n",
    "\n",
    "    return label_features, feature_names, label_encoders"
   ],
   "id": "4c38f197a2387fca",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:48.216037Z",
     "start_time": "2025-06-30T07:57:48.214249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_texts(tokens: List[Dict]) -> List[str]:\n",
    "    \"\"\"Extract text content from tokens.\"\"\"\n",
    "    return [token['token'] for token in tokens]"
   ],
   "id": "fe1a3f128bbdecc2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:48.682375Z",
     "start_time": "2025-06-30T07:57:48.680350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_semantic_embeddings(model: SentenceTransformer, texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"Generate semantic embeddings from text.\"\"\"\n",
    "    print(\"Generating semantic embeddings...\")\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    print(f\"Semantic embeddings shape: {embeddings.shape}\")\n",
    "    return embeddings"
   ],
   "id": "153d6675e3064a91",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:49.039456Z",
     "start_time": "2025-06-30T07:57:49.037484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_embeddings(semantic_embeddings: np.ndarray,\n",
    "                       label_features: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Combine semantic embeddings with label features.\"\"\"\n",
    "    if label_features.size > 0:\n",
    "        print(\"Combining semantic and label features...\")\n",
    "        combined = np.concatenate([semantic_embeddings, label_features], axis=1)\n",
    "    else:\n",
    "        combined = semantic_embeddings\n",
    "\n",
    "    print(f\"Final embedding shape: {combined.shape}\")\n",
    "    return combined"
   ],
   "id": "2e8758ad829d5c87",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:50.086292Z",
     "start_time": "2025-06-30T07:57:50.082826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_embeddings(embeddings: np.ndarray,\n",
    "                    texts: List[str],\n",
    "                    feature_names: List[str],\n",
    "                    model_tier: str,\n",
    "                    output_dir: str = \"embeddings_output\") -> Dict[str, str]:\n",
    "    \"\"\"Save embeddings and metadata to files.\"\"\"\n",
    "    output_path = Path(output_dir) / model_tier\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save embeddings\n",
    "    embedding_file = output_path / f\"embeddings_{model_tier}1.npy\"\n",
    "    np.save(embedding_file, embeddings)\n",
    "\n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'model_tier': model_tier,\n",
    "        'model_name': MODEL_CONFIGS[model_tier],\n",
    "        'embedding_dim': embeddings.shape[1],\n",
    "        'label_features': len(feature_names),\n",
    "        'num_tokens': len(texts),\n",
    "        'feature_names': feature_names\n",
    "    }\n",
    "\n",
    "    metadata_file = output_path / f\"metadata_{model_tier}.json\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    # Save token mapping\n",
    "    token_df = pd.DataFrame({\n",
    "        'index': range(len(texts)),\n",
    "        'token': texts,\n",
    "        'embedding_file': str(embedding_file)\n",
    "    })\n",
    "    token_file = output_path / f\"token_mapping_{model_tier}.csv\"\n",
    "    token_df.to_csv(token_file, index=False)\n",
    "\n",
    "    file_paths = {\n",
    "        'embeddings': str(embedding_file),\n",
    "        'metadata': str(metadata_file),\n",
    "        'token_mapping': str(token_file)\n",
    "    }\n",
    "\n",
    "    print(f\"Saved embeddings to {embedding_file}\")\n",
    "    print(f\"Saved metadata to {metadata_file}\")\n",
    "    print(f\"Saved token mapping to {token_file}\")\n",
    "\n",
    "    return file_paths"
   ],
   "id": "41350e2c47a17482",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:50.986380Z",
     "start_time": "2025-06-30T07:57:50.984648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_saved_embeddings(embedding_file: str) -> np.ndarray:\n",
    "    \"\"\"Load previously saved embeddings.\"\"\"\n",
    "    return np.load(embedding_file)"
   ],
   "id": "828762df47966854",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:51.679651Z",
     "start_time": "2025-06-30T07:57:51.677224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_embedding_stats(embeddings: np.ndarray) -> Dict:\n",
    "    \"\"\"Get basic statistics about embeddings.\"\"\"\n",
    "    return {\n",
    "        'shape': embeddings.shape,\n",
    "        'mean': embeddings.mean(),\n",
    "        'std': embeddings.std(),\n",
    "        'min': embeddings.min(),\n",
    "        'max': embeddings.max(),\n",
    "        'memory_mb': embeddings.nbytes / (1024 * 1024)}"
   ],
   "id": "c85e61f1926272d4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:52.459340Z",
     "start_time": "2025-06-30T07:57:52.456931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quick workflow functions for common operations\n",
    "def create_full_embeddings(json_path: str,\n",
    "                           model_tier: str = \"performance\",\n",
    "                           output_dir: str = \"embeddings_output\") -> Tuple[np.ndarray, Dict[str, str]]:\n",
    "    \"\"\"Complete workflow: JSON -> embeddings -> saved files.\"\"\"\n",
    "\n",
    "    # Load data\n",
    "    tokens = load_json_data(json_path)\n",
    "    texts = extract_texts(tokens)\n",
    "\n",
    "    # Setup model\n",
    "    model = setup_model(model_tier)\n",
    "\n",
    "    # Extract features\n",
    "    label_features, feature_names, _ = extract_label_features(tokens)\n",
    "\n",
    "    # Create embeddings\n",
    "    semantic_embeddings = create_semantic_embeddings(model, texts)\n",
    "    final_embeddings = combine_embeddings(semantic_embeddings, label_features)\n",
    "\n",
    "    # Save results\n",
    "    file_paths = save_embeddings(\n",
    "        final_embeddings, texts, feature_names, model_tier, output_dir\n",
    "    )\n",
    "\n",
    "    return final_embeddings, file_paths"
   ],
   "id": "94598927b47422b3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:57:53.135984Z",
     "start_time": "2025-06-30T07:57:53.133572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_model_tiers(json_path: str, output_dir: str = \"embeddings_output\"):\n",
    "    \"\"\"Generate embeddings with both model tiers for comparison.\"\"\"\n",
    "\n",
    "    print(\"=== Lightweight Model ===\")\n",
    "    embeddings_light, files_light = create_full_embeddings(\n",
    "        json_path, \"lightweight\", output_dir\n",
    "    )\n",
    "\n",
    "    print(f\"\\nLightweight stats: {get_embedding_stats(embeddings_light)}\")\n",
    "\n",
    "    print(\"\\n=== Performance Model ===\")\n",
    "    embeddings_perf, files_perf = create_full_embeddings(\n",
    "        json_path, \"performance\", output_dir\n",
    "    )\n",
    "\n",
    "    print(f\"\\nPerformance stats: {get_embedding_stats(embeddings_perf)}\")\n",
    "\n",
    "    return {\n",
    "        'lightweight': {'embeddings': embeddings_light, 'files': files_light},\n",
    "        'performance': {'embeddings': embeddings_perf, 'files': files_perf}\n",
    "    }"
   ],
   "id": "a26d1b2d7c3c630c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T14:33:07.029821Z",
     "start_time": "2025-07-06T14:32:54.133898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#embeddings0, files0 = create_full_embeddings(\"./output.json\", \"performance\", \"embeddings_output/v0\")\n",
    "embeddings1, files1 = create_full_embeddings(\"./output1_processed_first.json\", \"performance\", \"embeddings_output/v1\")\n",
    "embeddings2, files2 = create_full_embeddings(\"./output2_processed_first.json\", \"performance\", \"embeddings_output/v2\")\n",
    "embeddings3, files3 = create_full_embeddings(\"./full_story_output.json\", \"performance\", \"embeddings_output/v3\")"
   ],
   "id": "cf76542495568286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: JSON structure type: <class 'dict'>\n",
      "DEBUG: JSON keys: ['metadata', 'tokens']\n",
      "DEBUG: Found 'tokens' key with 1182 items\n",
      "Loaded 1182 tokens from ./output1_processed_first.json\n",
      "DEBUG: Unique token texts after loading: 1134\n",
      "DEBUG: DUPLICATION DETECTED IN LOADING! 1182 total vs 1134 unique\n",
      "DEBUG: Found 22 duplicated texts:\n",
      "  'and...' appears 4 times\n",
      "  'Carmen began...' appears 2 times\n",
      "  'to read....' appears 2 times\n",
      "Loading BAAI/bge-large-en-v1.5 on mps...\n",
      "Model loaded. Embedding dimension: 1024\n",
      "Extracted 8 label features\n",
      "Generating semantic embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/37 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88465c7f20ea404581b76c86f031899a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic embeddings shape: (1182, 1024)\n",
      "Combining semantic and label features...\n",
      "Final embedding shape: (1182, 1032)\n",
      "Saved embeddings to embeddings_output/v1/performance/embeddings_performance1.npy\n",
      "Saved metadata to embeddings_output/v1/performance/metadata_performance.json\n",
      "Saved token mapping to embeddings_output/v1/performance/token_mapping_performance.csv\n",
      "DEBUG: JSON structure type: <class 'dict'>\n",
      "DEBUG: JSON keys: ['metadata', 'tokens']\n",
      "DEBUG: Found 'tokens' key with 1182 items\n",
      "Loaded 1182 tokens from ./output2_processed_first.json\n",
      "DEBUG: Unique token texts after loading: 1134\n",
      "DEBUG: DUPLICATION DETECTED IN LOADING! 1182 total vs 1134 unique\n",
      "DEBUG: Found 22 duplicated texts:\n",
      "  'and...' appears 4 times\n",
      "  'Carmen began...' appears 2 times\n",
      "  'to read....' appears 2 times\n",
      "Loading BAAI/bge-large-en-v1.5 on mps...\n",
      "Model loaded. Embedding dimension: 1024\n",
      "Extracted 8 label features\n",
      "Generating semantic embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/37 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d870d6f3957a4581af1d39c470d2293b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic embeddings shape: (1182, 1024)\n",
      "Combining semantic and label features...\n",
      "Final embedding shape: (1182, 1032)\n",
      "Saved embeddings to embeddings_output/v2/performance/embeddings_performance1.npy\n",
      "Saved metadata to embeddings_output/v2/performance/metadata_performance.json\n",
      "Saved token mapping to embeddings_output/v2/performance/token_mapping_performance.csv\n",
      "DEBUG: JSON structure type: <class 'dict'>\n",
      "DEBUG: JSON keys: ['metadata', 'tokens']\n",
      "DEBUG: Found 'tokens' key with 1182 items\n",
      "Loaded 1182 tokens from ./full_story_output.json\n",
      "DEBUG: Unique token texts after loading: 1134\n",
      "DEBUG: DUPLICATION DETECTED IN LOADING! 1182 total vs 1134 unique\n",
      "DEBUG: Found 22 duplicated texts:\n",
      "  'and...' appears 4 times\n",
      "  'Carmen began...' appears 2 times\n",
      "  'to read....' appears 2 times\n",
      "Loading BAAI/bge-large-en-v1.5 on mps...\n",
      "Model loaded. Embedding dimension: 1024\n",
      "Extracted 8 label features\n",
      "Generating semantic embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/37 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd1c192221f84576947cd7e140334d59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic embeddings shape: (1182, 1024)\n",
      "Combining semantic and label features...\n",
      "Final embedding shape: (1182, 1032)\n",
      "Saved embeddings to embeddings_output/v3/performance/embeddings_performance1.npy\n",
      "Saved metadata to embeddings_output/v3/performance/metadata_performance.json\n",
      "Saved token mapping to embeddings_output/v3/performance/token_mapping_performance.csv\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "762ed431312d4602"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
