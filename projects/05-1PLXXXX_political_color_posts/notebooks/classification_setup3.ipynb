{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u-fMPSLrp0uO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XCzYvHdXp3dL"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/IvaroEkel/Probabilistic-Machine-Learning_lecture-PROJECTS/refs/heads/main/projects/05-1PLXXXX_political_color_posts/data/final-features-hsv.csv'\n",
        "df = pd.read_csv(url)\n",
        "X_full = df[[f'feature_{i}' for i in range(13)]]\n",
        "y_full = df['party']\n",
        "relevant_full = df['relevant']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MukdajBxp_4R"
      },
      "outputs": [],
      "source": [
        "# choose data for training and test sets (depending on column 'relevant')\n",
        "train_relevant = 1\n",
        "test_relevant = 1\n",
        "\n",
        "if train_relevant == test_relevant:\n",
        "    mask = (relevant_full == train_relevant)\n",
        "    X_selected = X_full[mask]\n",
        "    y_selected = y_full[mask]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_selected, y_selected, stratify=y_selected, test_size=0.2, random_state=42)\n",
        "else:\n",
        "    X_train = X_full[relevant_full == train_relevant]\n",
        "    y_train = y_full[relevant_full == train_relevant]\n",
        "    X_test = X_full[relevant_full == test_relevant]\n",
        "    y_test = y_full[relevant_full == test_relevant]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b0JINW4aqCDn"
      },
      "outputs": [],
      "source": [
        "def extract_metrics(report):\n",
        "    metrics = {}\n",
        "    lines = report.split(\"\\n\")\n",
        "    for line in lines:\n",
        "        parts = line.split()\n",
        "        if len(parts) >= 5:\n",
        "            label = parts[0]\n",
        "            try:\n",
        "                precision = float(parts[1])\n",
        "                recall = float(parts[2])\n",
        "                f1_score = float(parts[3])\n",
        "                support = int(parts[4])\n",
        "                metrics[label] = {\n",
        "                    'Precision': precision,\n",
        "                    'Recall': recall,\n",
        "                    'F1-Score': f1_score,\n",
        "                    'Support': support\n",
        "                }\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGnG8p28qEUz",
        "outputId": "4466f0f2-8966-419b-973d-db27654ed39f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Random Forest ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         afd       0.84      0.45      0.58       182\n",
            "         cdu       0.61      0.60      0.61       512\n",
            "         csu       0.61      0.85      0.71       765\n",
            "         fdp       0.88      0.90      0.89       611\n",
            "      gruene       0.99      0.69      0.81       297\n",
            "       linke       0.72      0.60      0.65       364\n",
            "         spd       0.82      0.59      0.69       272\n",
            "\n",
            "    accuracy                           0.72      3003\n",
            "   macro avg       0.78      0.67      0.71      3003\n",
            "weighted avg       0.75      0.72      0.72      3003\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Random Forest\n",
        "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "report_rf = classification_report(y_test, y_pred_rf)\n",
        "metrics_rf = extract_metrics(report_rf)\n",
        "print(\"=== Random Forest ===\")\n",
        "print(report_rf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. XGBoost\n",
        "# Encode the target variable\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_test_encoded = le.transform(y_test)\n",
        "\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "xgb.fit(X_train, y_train_encoded)\n",
        "y_pred_xgb_encoded = xgb.predict(X_test)\n",
        "\n",
        "# Decode the predictions back to original labels for classification report\n",
        "y_pred_xgb = le.inverse_transform(y_pred_xgb_encoded)\n",
        "\n",
        "report_xgb = classification_report(y_test, y_pred_xgb)\n",
        "metrics_xgb = extract_metrics(report_xgb)\n",
        "print(\"=== XGBoost ===\")\n",
        "print(report_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ABjm3gmmB4k",
        "outputId": "9b419fff-e11b-480e-d4e8-1054f4dbf940"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [07:58:32] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== XGBoost ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         afd       0.75      0.49      0.59       182\n",
            "         cdu       0.62      0.64      0.63       512\n",
            "         csu       0.64      0.81      0.71       765\n",
            "         fdp       0.91      0.89      0.90       611\n",
            "      gruene       0.91      0.74      0.82       297\n",
            "       linke       0.70      0.63      0.66       364\n",
            "         spd       0.76      0.61      0.68       272\n",
            "\n",
            "    accuracy                           0.73      3003\n",
            "   macro avg       0.76      0.69      0.71      3003\n",
            "weighted avg       0.74      0.73      0.73      3003\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OMk7jFJqG0j",
        "outputId": "6a5040df-7603-4dfc-dbf0-e9f8621ce9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Support Vector Machine (SVM) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         afd       0.44      0.65      0.52       182\n",
            "         cdu       0.49      0.68      0.57       512\n",
            "         csu       0.73      0.62      0.67       765\n",
            "         fdp       0.90      0.83      0.86       611\n",
            "      gruene       0.84      0.71      0.77       297\n",
            "       linke       0.60      0.46      0.52       364\n",
            "         spd       0.65      0.65      0.65       272\n",
            "\n",
            "    accuracy                           0.67      3003\n",
            "   macro avg       0.66      0.66      0.65      3003\n",
            "weighted avg       0.69      0.67      0.67      3003\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. Support Vector Machine (SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "svm = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "report_svm = classification_report(y_test, y_pred_svm)\n",
        "metrics_svm = extract_metrics(report_svm)\n",
        "print(\"=== Support Vector Machine (SVM) ===\")\n",
        "print(report_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAvppV-9qIwy",
        "outputId": "0de243e0-aa5c-4476-c93d-bce3d6df9b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MLP Classifier ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         afd       0.57      0.52      0.54       182\n",
            "         cdu       0.55      0.62      0.58       512\n",
            "         csu       0.66      0.72      0.69       765\n",
            "         fdp       0.88      0.85      0.86       611\n",
            "      gruene       0.81      0.73      0.77       297\n",
            "       linke       0.58      0.55      0.57       364\n",
            "         spd       0.68      0.57      0.62       272\n",
            "\n",
            "    accuracy                           0.68      3003\n",
            "   macro avg       0.68      0.65      0.66      3003\n",
            "weighted avg       0.69      0.68      0.68      3003\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4. MLP Classifier\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(128, 64),\n",
        "    activation='relu',\n",
        "    learning_rate_init=0.001,\n",
        "    max_iter=1000,\n",
        "    alpha=0.0001,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test_scaled)\n",
        "report_mlp = classification_report(y_test, y_pred_mlp)\n",
        "metrics_mlp = extract_metrics(report_mlp)\n",
        "print(\"=== MLP Classifier ===\")\n",
        "print(report_mlp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Linear Discriminant Analysis (LDA)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train_scaled, y_train)\n",
        "y_pred_lda = lda.predict(X_test_scaled)\n",
        "report_lda = classification_report(y_test, y_pred_lda)\n",
        "metrics_lda = extract_metrics(report_lda)\n",
        "print(\"=== Linear Discriminant Analysis (LDA) ===\")\n",
        "print(report_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJrx3GbUMC-I",
        "outputId": "835ede5f-5a6e-4df3-81c4-7bf0a4cd17f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Linear Discriminant Analysis (LDA) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         afd       0.64      0.10      0.17       182\n",
            "         cdu       0.36      0.19      0.24       512\n",
            "         csu       0.45      0.80      0.57       765\n",
            "         fdp       0.76      0.62      0.69       611\n",
            "      gruene       0.58      0.49      0.53       297\n",
            "       linke       0.42      0.34      0.38       364\n",
            "         spd       0.52      0.56      0.54       272\n",
            "\n",
            "    accuracy                           0.51      3003\n",
            "   macro avg       0.53      0.44      0.45      3003\n",
            "weighted avg       0.52      0.51      0.48      3003\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRYegJB5pjU7",
        "outputId": "20afb47a-f250-4e94-9753-05063168d75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Modellvergleich ===\n",
            "         Random Forest   SVM   MLP  XGBoost   LDA  Average\n",
            "fdp               0.89  0.86  0.86     0.90  0.69     0.84\n",
            "gruene            0.81  0.77  0.77     0.82  0.53     0.74\n",
            "csu               0.71  0.67  0.69     0.71  0.57     0.67\n",
            "spd               0.69  0.65  0.62     0.68  0.54     0.64\n",
            "Average           0.71  0.65  0.66     0.71  0.45     0.64\n",
            "linke             0.65  0.52  0.57     0.66  0.38     0.56\n",
            "cdu               0.61  0.57  0.58     0.63  0.24     0.53\n",
            "afd               0.58  0.52  0.54     0.59  0.17     0.48\n"
          ]
        }
      ],
      "source": [
        "metrics_all = {}\n",
        "\n",
        "for label in metrics_rf:\n",
        "    metrics_all[label] = {\n",
        "        'Random Forest': metrics_rf[label]['F1-Score'],\n",
        "        'SVM': metrics_svm.get(label, {}).get('F1-Score', 0),\n",
        "        'MLP': metrics_mlp.get(label, {}).get('F1-Score', 0),\n",
        "        'XGBoost': metrics_xgb[label]['F1-Score'],\n",
        "        'LDA': metrics_lda[label]['F1-Score']\n",
        "    }\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_all).T\n",
        "\n",
        "metrics_df[\"Average\"] = metrics_df.mean(axis=1)\n",
        "\n",
        "average_row = metrics_df.mean(numeric_only=True)\n",
        "average_row.name = \"Average\"\n",
        "metrics_df = pd.concat([metrics_df, average_row.to_frame().T])\n",
        "\n",
        "metrics_df = metrics_df.sort_values(by=\"Average\", ascending=False)\n",
        "\n",
        "# Output\n",
        "print(\"=== Modellvergleich ===\")\n",
        "print(metrics_df.round(2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}