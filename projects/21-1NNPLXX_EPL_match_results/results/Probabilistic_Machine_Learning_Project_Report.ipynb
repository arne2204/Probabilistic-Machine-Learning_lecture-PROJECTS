{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HllaHun_QKXK"
      },
      "source": [
        "# Probabilistic Machine Learning - Project Report\n",
        "\n",
        "**Course:** Probabilistic Machine Learning (SoSe 2025)\n",
        "\n",
        "**Lecturer:** Alvaro Diaz-Ruelas\n",
        "\n",
        "**Student(s) Name(s):**  Niklas Nesseler, Lauren Pommer\n",
        "\n",
        "**GitHub Username(s):**  @NiklasNesseler\n",
        "\n",
        "**Date:**  20th of July 2025\n",
        "\n",
        "**PROJECT-ID:** 21-1NNPLXX_EPL_match_results\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9mvF1sORTHr"
      },
      "source": [
        "## 1. Introduction\n",
        "\n",
        "\n",
        "### Brief description of the dataset and problem\n",
        "The dataset contains detailed match-level data from the English Premier League spanning from September 2020 to May 2024, comprising 4,788 entries and 28 features. Key information includes match context (teams, venue, round), results (goals for/against, win/draw/loss), and performance metrics (xG, possession, shots, etc.).\n",
        "The task is to use this dataset to predict match outcomes based on pre-match or in-game statistics.\n",
        "\n",
        "### Motivation for our project\n",
        "The Premier League is one of the most watched and competitive football leagues globally. Predicting match results has broad applications in sports analytics, betting, and fan engagement. It also serves as a solid real-world use case for machine learning classification.\n",
        "\n",
        "### Hypothesis or research question\n",
        "Can shallow learning models such as SVMs and XGBoost accurately predict the match outcome (win/draw/loss) using features like xG, possession, venue, and team-related context? Will XGBoost outperform SVC?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWmVdPMYRW4u"
      },
      "source": [
        "\n",
        "## 2. Data Loading and Exploration\n",
        "\n",
        "The dataset was loaded using pandas.\n",
        "Initial exploration showed 4,788 entries with 28 features. Basic statistics and structure checks were conducted (df.info(), .describe()). The dataset includes match-level information such as team names, match date, xG, possession, goals, and outcome. No critical features were missing, and minor data cleaning steps were planned for preprocessing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRUhDk7WRbiZ"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "### Timeframe Filtering\n",
        "* The dataset was filtered to include only matches from August 5, 2022 to May 19, 2024.\n",
        "\n",
        "* This reduced the number of entries from 4,788 to 1,520.\n",
        "\n",
        "* Reason: Focus on recent seasons (2022/23 and 2023/24) to ensure relevance and reflect current playing styles, tactics, and team dynamics.\n",
        "\n",
        "* Trade-off: Fewer samples, but higher quality and temporal consistency.\n",
        "\n",
        "\n",
        "### Match Outcome Encoding\n",
        "* Original results (W/D/L) were encoded as:\n",
        "\n",
        "* Win = +1, Draw = 0, Loss = −1\n",
        "\n",
        "* Purpose: Enables classification models (e.g., SVM, XGBoost) and maintains class balance (591 wins, 591 losses).\n",
        "\n",
        "### De-duplication & Match-Based Restructuring\n",
        "* The dataset is team-centric and contained duplicates.\n",
        "\n",
        "* Transformed into a match-based structure, sorted by date.\n",
        "\n",
        "* Duplicates were removed to ensure clean, non-redundant records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtlE5KFnRfhM"
      },
      "source": [
        "## 4. Feature Engineering\n",
        "\n",
        "### Engineered Features\n",
        "We developed several key features to capture different dimensions of team performance and match context:\n",
        "\n",
        "#### **Recent Performance Indicators**\n",
        "**Recent Form (Last 5 Matches)**\n",
        "* Type: Rolling average points metric\n",
        "* Idea: Captures short-term team momentum using a standardized scoring system (Win=3, Draw=1, Loss=0)\n",
        "* Feature: form_last_5_avg\n",
        "* Why it matters: Recent form often better predicts immediate outcomes than season-long statistics, reflecting current squad fitness, confidence, and tactical adjustments.\n",
        "\n",
        "#### **Venue-Specific Strength Metrics**\n",
        "**Home vs Away Performance**\n",
        "* Type: Separate strength calculations by venue\n",
        "* Idea: Teams often perform differently at home versus away due to crowd support, travel fatigue, and familiarity with conditions\n",
        "* Features: home_strength and away_strength\n",
        "* Calculation: Average points per game segmented by venue from historical matches\n",
        "\n",
        "#### **Advanced Attacking Metrics**\n",
        "**Goals and Expected Goals (Last 10 Matches)**\n",
        "* Type: Rolling averages of actual and expected performance\n",
        "* Idea: Combines recent scoring output with underlying shot quality to assess true attacking strength\n",
        "* Features: avg_goals_last_10 and avg_xg_last_10\n",
        "* Why it works: The gap between actual goals and expected goals reveals whether a team is over/under-performing their chances, indicating sustainability of current form.\n",
        "\n",
        "#### **Defensive Stability Indicators**\n",
        "**Goals Conceded (Last 10 Matches)**\n",
        "* Type: Rolling defensive performance metric\n",
        "* Idea: Recent defensive record as a predictor of future vulnerability\n",
        "* Feature: avg_goals_conceded_last_10\n",
        "* Application: Quantifies defensive consistency and identifies teams in poor defensive form.\n",
        "\n",
        "#### **Tactical Style Indicators**\n",
        "**Possession Control (Last 10 Matches)**\n",
        "* Type: Rolling average of ball possession percentage\n",
        "* Idea: Reflects team's tactical approach and ability to control game tempo\n",
        "* Feature: avg_possession_last_10\n",
        "* Data handling: Missing values filled with neutral 50% when fewer than 10 prior matches available\n",
        "* Insight: High possession often correlates with territorial dominance and scoring opportunities.\n",
        "\n",
        "#### **Historical Context Features**\n",
        "**Head-to-Head Performance**\n",
        "* Type: Normalized historical matchup score\n",
        "* Idea: Captures psychological advantages, tactical familiarity, and stylistic matchups between specific teams\n",
        "* Application: Accounts for rivalry dynamics and historical dominance patterns not reflected in current form alone.\n",
        "\n",
        "#### **Officiating Context**\n",
        "**Referee Bias Indicators**\n",
        "* Type: Statistical analysis of referee-team win rate patterns\n",
        "* Idea: Identifies referees with statistically significant deviations in team-specific outcomes\n",
        "* Trade-Off: Correlation may reflect that certain referees officiate more high-profile matches involving stronger teams rather than actual bias\n",
        "* Usage: Included for completeness but treated as contextual rather than predictive.\n",
        "\n",
        "### Data Leakage Prevention\n",
        "**Removed Future Information**\n",
        "* Challenge: Ensuring model only uses information available at prediction time\n",
        "* Dropped features:home_goals, away_goals, home_xg, away_xg, home_poss\n",
        "* These represent match outcomes rather than pre-match predictors, preventing overfitting and ensuring real-world applicability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndWeYCrFRhWa"
      },
      "source": [
        "## 5. Probabilistic Modeling Approach\n",
        "\n",
        "### Chosen Models\n",
        "\n",
        "We implemented and evaluated two machine learning models to predict Premier League match outcomes:\n",
        "\n",
        "#### 1. **Support Vector Machines (SVM)**\n",
        "\n",
        "* **Type**: Linear / non-linear classifier\n",
        "* **Core Idea**: Finds the *optimal hyperplane* that best separates classes in the feature space.\n",
        "* **Why it fits**:\n",
        "\n",
        "  * Match outcomes are naturally **separable classes** (Win, Draw, Loss).\n",
        "  * Performs well on **small to medium datasets** (\\~760 samples).\n",
        "  * Effective with **engineered, high-dimensional features**.\n",
        "  * Provides **interpretable decision boundaries** and insights into feature importance.\n",
        "\n",
        "#### 2. **XGBoost (Extreme Gradient Boosting)**\n",
        "\n",
        "* **Type**: Ensemble of boosted decision trees\n",
        "* **Core Idea**: Builds trees sequentially, each correcting the previous one's errors.\n",
        "* **Why it fits**:\n",
        "\n",
        "  * Captures **complex, non-linear relationships**.\n",
        "  * Efficiently handles **numerical and categorical features** without heavy preprocessing.\n",
        "  * Learns **interactions between features** automatically.\n",
        "  * Often achieves **state-of-the-art performance** on structured/tabular data.\n",
        "\n",
        "### Feature Importance Analysis\n",
        "\n",
        "To interpret model behavior and guide feature selection, we used three methods:\n",
        "\n",
        "* **Random Forest Feature Importance** – based on impurity reduction.\n",
        "* **Mutual Information** – measures non-linear dependency between input and target.\n",
        "* **Pearson Correlation** – measures linear association between feature and target.\n",
        "\n",
        "All three were normalized and compared across four visualizations.\n",
        "\n",
        "#### Top-Ranked Features (Consensus)\n",
        "\n",
        "Based on average rank across all three methods:\n",
        "\n",
        "1. home_avg_goals_10\n",
        "2. home_avg_xg_10\n",
        "3. away_avg_xg_10\n",
        "4. home_team_form\n",
        "5. away_avg_goals_10\n",
        "6. away_team_form\n",
        "7. home_avg_conceded_10\n",
        "8. h2h_stat\n",
        "9. away_avg_conceded_10\n",
        "10. home_avg_possession_10\n",
        "\n",
        "These features were included in both models.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgVmBrEoRlbi"
      },
      "source": [
        "# 6. Model Training and Evaluation\n",
        "\n",
        "## Training Process\n",
        "\n",
        "Both models were trained using the same 80/20 train-test split, resulting in 608 training samples and 152 test samples. The training process involved several key steps:\n",
        "\n",
        "### Support Vector Machine (SVM):\n",
        "* **Feature scaling**: StandardScaler was applied to normalize all features, which is crucial for SVM performance\n",
        "* **Baseline model**: Initial RBF kernel SVM with default parameters achieved 69.08% accuracy\n",
        "* **Hyperparameter optimization**: GridSearchCV with 5-fold cross-validation tested 72 parameter combinations across:\n",
        "  * C values: [0.1, 1, 10, 100]\n",
        "  * Gamma values: ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
        "  * Kernels: ['rbf', 'poly', 'sigmoid']\n",
        "\n",
        "### XGBoost:\n",
        "* **No preprocessing required**: XGBoost handles mixed data types and scaling internally\n",
        "* **Label remapping**: Target labels were converted from {-1, 0, 1} to {0, 1, 2} for XGBoost compatibility\n",
        "* **Baseline model**: Default XGBoost classifier achieved 66.45% accuracy\n",
        "* **Hyperparameter optimization**: GridSearchCV with 5-fold cross-validation tested 16 parameter combinations across:\n",
        "  * Number of estimators: [100, 200]\n",
        "  * Maximum depth: [4, 6]\n",
        "  * Learning rate: [0.1, 0.2]\n",
        "  * Subsample ratio: [0.8, 1.0]\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "### Performance Metrics\n",
        "\n",
        "**SVM Results:**\n",
        "* **Best parameters**: C=1, gamma=0.01, kernel='rbf'\n",
        "* **Test accuracy**: 66.45%\n",
        "* **Cross-validation score**: 64.96% ± 4.07%\n",
        "* **Class-specific performance**:\n",
        "  * Away Win: 63% precision, 78% recall\n",
        "  * Draw: 0% precision, 0% recall (complete failure)\n",
        "  * Home Win: 68% precision, 90% recall\n",
        "\n",
        "**XGBoost Results:**\n",
        "* **Best parameters**: learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0\n",
        "* **Test accuracy**: 67.11%\n",
        "* **Cross-validation score**: 61.68% ± 3.79%\n",
        "* **Class-specific performance**:\n",
        "  * Away Win: 65% precision, 80% recall\n",
        "  * Draw: 45% precision, 15% recall (poor but not zero)\n",
        "  * Home Win: 71% precision, 83% recall\n",
        "\n",
        "### Key Performance Insights\n",
        "\n",
        "1. **Draw prediction challenge**: Both models struggle significantly with predicting draws, which is common in football prediction due to the inherent randomness of draw outcomes.\n",
        "\n",
        "2. **Home advantage bias**: Both models show strong performance for home wins, reflecting the statistical home advantage in football.\n",
        "\n",
        "3. **Model comparison**: While XGBoost achieved slightly higher test accuracy (67.11% vs 66.45%), SVM showed better cross-validation stability with higher CV scores.\n",
        "\n",
        "### Feature Importance Analysis\n",
        "\n",
        "**SVM Feature Importance** (using linear kernel approximation):\n",
        "1. **home_team_form** (30.44%): Dominant feature indicating recent home team performance\n",
        "2. **away_team_form** (16.32%): Second most important, showing away team recent form\n",
        "3. **referee_encoded** (6.82%): Referee influence on match outcomes\n",
        "4. **home_avg_goals_10** (6.28%): Home team's recent scoring ability\n",
        "5. **home_avg_possession_10** (5.61%): Home team's ball control metrics\n",
        "\n",
        "**XGBoost Feature Importance**:\n",
        "1. **home_team_form** (21.40%): Consistently the most important feature\n",
        "2. **away_team_form** (12.50%): Second most important across both models\n",
        "3. **home_avg_goals_10** (6.01%): Recent goal-scoring form\n",
        "4. **away_avg_goals_10** (5.87%): Away team scoring metrics\n",
        "5. **home_avg_conceded_10** (5.72%): Defensive performance metrics\n",
        "\n",
        "### Cross-Validation and Uncertainty Quantification\n",
        "\n",
        "**Cross-Validation Results:**\n",
        "* **SVM**: 5-fold CV scores ranged from 61.98% to 68.03%, with mean 64.96% ± 2.04%\n",
        "* **XGBoost**: 5-fold CV scores ranged from 59.50% to 64.46%, with mean 61.68% ± 1.90%\n",
        "\n",
        "**Confidence Analysis:**\n",
        "* **SVM**: Mean confidence of 2.21 (decision function scores), with all predictions showing high confidence (>0.8)\n",
        "* **XGBoost**: Mean confidence of 74.26%, with 73 high-confidence predictions (>0.8) and 23 low-confidence predictions (<0.5)\n",
        "\n",
        "**Temporal Stability**: Monthly accuracy analysis revealed significant variation over time, with accuracy ranging from 41.7% to 100% depending on the month, suggesting potential seasonal effects or data drift that should be monitored in production deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0MIdzBjRnGK"
      },
      "source": [
        "# 7. Results\n",
        "\n",
        "## Key Findings\n",
        "\n",
        "Both machine learning models achieved comparable performance on football match outcome prediction, with test accuracies around 66-67%. However, significant class imbalance challenges emerged, particularly in predicting draw outcomes.\n",
        "\n",
        "### Overall Performance:\n",
        "* **XGBoost**: 67.11% test accuracy (best performing)\n",
        "* **SVM**: 66.45% test accuracy\n",
        "* Both models significantly outperformed random guessing (33.3% for 3-class problem)\n",
        "\n",
        "### Critical Insight Draw Prediction Challenge:\n",
        "The most striking finding was the models' inability to reliably predict draws. SVM completely failed to predict any draws (0% precision/recall), while XGBoost managed only 45% precision and 15% recall for draw outcomes. This reflects the inherent unpredictability of drawn matches in football.\n",
        "\n",
        "**Feature Importance Consistency:**\n",
        "Both models consistently identified **team form** as the dominant predictive factor, with home and away team form accounting for 46.76% (SVM) and 33.90% (XGBoost) of total feature importance respectively.\n",
        "\n",
        "## Model Comparison\n",
        "\n",
        "| Metric | SVM | XGBoost | Winner |\n",
        "|--------|-----|---------|--------|\n",
        "| **Test Accuracy** | 66.45% | 67.11% | XGBoost |\n",
        "| **Cross-Validation** | 64.96% ± 2.04% | 61.68% ± 1.90% | SVM |\n",
        "| **Draw Prediction** | Complete failure | Poor but functional | XGBoost |\n",
        "| **Confidence Estimates** | Limited interpretability | Probabilistic outputs | XGBoost |\n",
        "| **Training Efficiency** | Requires scaling | No preprocessing | XGBoost |\n",
        "\n",
        "**Recommendation**: XGBoost emerges as the preferred model due to its marginally better test performance, ability to predict draws (albeit poorly), and superior interpretability through native probability estimates. However, the performance gap is minimal, and SVM's better cross-validation stability suggests both models are viable options for this prediction task.\n",
        "\n",
        "The results highlight that football match prediction remains a challenging domain where even sophisticated machine learning approaches struggle with the sport's inherent unpredictability, particularly for draw outcomes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAD7WOFRour"
      },
      "source": [
        "# 8. Discussion\n",
        "\n",
        "## Interpretation of Results\n",
        "\n",
        "The 67% accuracy achieved represents a meaningful improvement over random chance, but highlights the fundamental challenge of football prediction. The models' strong performance on home wins (83-90% recall) confirms the well-documented home advantage effect, while the complete failure to predict draws reflects football's inherent randomness where evenly matched teams often produce unpredictable outcomes.\n",
        "\n",
        "The dominance of **team form** features (30-46% of model importance) validates the intuitive understanding that recent performance is the strongest predictor of future results. This aligns with football analytics literature emphasizing momentum and current squad fitness over historical statistics.\n",
        "\n",
        "## Limitations of the Approach\n",
        "\n",
        "### Data Limitations:\n",
        "* Missing crucial contextual factors: player injuries, transfers, motivation levels, and weather conditions\n",
        "* Limited historical depth may not capture long-term tactical evolution\n",
        "* No real-time data integration (lineups, pre-match news)\n",
        "\n",
        "### Methodological Constraints:\n",
        "* Class imbalance severely impacts draw prediction capability\n",
        "* Static feature engineering may miss complex temporal dependencies\n",
        "* Cross-validation shows temporal instability, suggesting potential data drift\n",
        "\n",
        "### Scope Restrictions:\n",
        "* Single league focus limits generalizability across different football cultures\n",
        "* Binary encoding of categorical variables loses nuanced team relationships\n",
        "\n",
        "## Possible Improvements and Extensions\n",
        "\n",
        "### Enhanced Feature Engineering:\n",
        "* Incorporate player-level statistics and injury reports\n",
        "* Add head-to-head historical matchup data\n",
        "* Include market odds as baseline probability estimates\n",
        "\n",
        "### Advanced Modeling Approaches:\n",
        "* Ensemble methods combining multiple algorithms\n",
        "* Deep learning with LSTM networks for temporal sequence modeling\n",
        "* Ordinal regression treating outcomes as ordered categories rather than independent classes\n",
        "\n",
        "### Real-World Deployment:\n",
        "* Live data integration for dynamic prediction updates\n",
        "* Confidence-based betting strategies focusing on high-certainty predictions\n",
        "* Multi-league expansion with transfer learning techniques\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4de-OwR1RqBG"
      },
      "source": [
        "## 9. Summary\n",
        "\n",
        "This project aimed to predict Premier League match outcomes using machine learning techniques on a comprehensive dataset spanning from 2022 to 2024. The study compared Support Vector Machines and XGBoost models to classify matches into three categories: home win, draw, and away win.\n",
        "\n",
        "### **Main Outcomes**\n",
        "\n",
        "**Model Performance**: Both models achieved comparable and meaningful results, with XGBoost slightly outperforming SVM. This represents a substantial improvement over random chance, demonstrating that machine learning can extract predictive signals from football data.\n",
        "\n",
        "**Feature Engineering Success**: The comprehensive feature engineering approach proved effective, with engineered features like recent team form, rolling performance metrics, and venue-specific strengths becoming the most important predictors. Team form features dominated both models, accounting for 30-46% of total feature importance, validating the intuitive understanding that recent performance is crucial for prediction.\n",
        "\n",
        "**Critical Challenge - Draw Prediction**: The most significant limitation was the models' inability to reliably predict draws. SVM completely failed to predict any draws, while XGBoost managed only modest performance. This reflects the inherent unpredictability of evenly matched contests in football.\n",
        "\n",
        "**Model Comparison**: XGBoost emerged as the preferred choice due to its marginally better accuracy, functional draw prediction capability, and superior interpretability through probabilistic outputs. However, SVM's better cross-validation stability suggests both models are viable options.\n",
        "\n",
        "**Key Insights**: The analysis confirmed several football analytics principles, including the strong home advantage effect and the dominance of recent form over historical statistics. The temporal instability observed in monthly accuracy variationshighlighted potential seasonal effects and data drift concerns for production deployment.\n",
        "\n",
        "**Limitations and Future Directions**: The study identified several areas for improvement, including the need for player-level data, injury reports, real-time information integration, and advanced modeling approaches like ensemble methods or deep learning architectures. The class imbalance problem and missing contextual factors remain significant challenges.\n",
        "\n",
        "Overall, the project successfully demonstrated that shallow machine learning techniques can provide meaningful insights into football match prediction, achieving accuracy levels that could be valuable for sports analytics applications, while also highlighting the sport's fundamental unpredictability that continues to challenge even sophisticated analytical approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. References\n",
        "\n",
        "https://www.kaggle.com/datasets/mhmdkardosha/premier-league-matches"
      ],
      "metadata": {
        "id": "UoF3z5pMtvvI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}