{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12785947,"sourceType":"datasetVersion","datasetId":8083584},{"sourceId":12786616,"sourceType":"datasetVersion","datasetId":8084045},{"sourceId":12788107,"sourceType":"datasetVersion","datasetId":8085067},{"sourceId":12788160,"sourceType":"datasetVersion","datasetId":8085102}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPyxCQYoMBLtt1Ayto5VwZB"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install optuna\n!pip install gpytorch","metadata":{"id":"xqXMutdkGoE3","executionInfo":{"status":"ok","timestamp":1755367912144,"user_tz":-120,"elapsed":110735,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"outputId":"7ad11888-3c2e-47fb-954b-225bb337460b","trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:12:31.853120Z","iopub.execute_input":"2025-08-22T12:12:31.853384Z","iopub.status.idle":"2025-08-22T12:13:45.738498Z","shell.execute_reply.started":"2025-08-22T12:12:31.853365Z","shell.execute_reply":"2025-08-22T12:13:45.737793Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\nCollecting gpytorch\n  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\nCollecting jaxtyping (from gpytorch)\n  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.3.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.2.2)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.15.3)\nCollecting linear-operator>=0.6 (from gpytorch)\n  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from linear-operator>=0.6->gpytorch) (2.6.0+cu124)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.6.0->gpytorch) (1.26.4)\nCollecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch)\n  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (1.13.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->linear-operator>=0.6->gpytorch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy>=1.6.0->gpytorch) (2024.2.0)\nDownloading gpytorch-1.14-py3-none-any.whl (277 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\nInstalling collected packages: wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, linear-operator, gpytorch\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed gpytorch-1.14 jaxtyping-0.3.2 linear-operator-0.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 wadler-lindig-0.1.7\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nfrom functools import reduce\nimport os\nimport joblib\nimport pickle\nfrom pathlib import Path\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nimport gpytorch\nfrom gpytorch.kernels import MaternKernel, PeriodicKernel, LinearKernel, ScaleKernel, MultitaskKernel, RBFKernel, AdditiveKernel\nfrom gpytorch.models import ApproximateGP\nfrom gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy, MultitaskVariationalStrategy, LMCVariationalStrategy\nfrom gpytorch.distributions import MultitaskMultivariateNormal\nfrom gpytorch.likelihoods import MultitaskGaussianLikelihood\nfrom gpytorch.mlls import VariationalELBO\nfrom gpytorch.means import ConstantMean\n\nfrom joblib import Parallel, delayed\nimport gc\nfrom scipy.stats import multivariate_normal\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom typing import Tuple\nfrom functools import partial\nfrom linear_operator.utils.errors import NotPSDError","metadata":{"id":"lji1yiK7FroQ","executionInfo":{"status":"ok","timestamp":1755367921858,"user_tz":-120,"elapsed":9699,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:13:56.875311Z","iopub.execute_input":"2025-08-22T12:13:56.876022Z","iopub.status.idle":"2025-08-22T12:13:56.882011Z","shell.execute_reply.started":"2025-08-22T12:13:56.875997Z","shell.execute_reply":"2025-08-22T12:13:56.881206Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#Laden der Rowwise Daten da bessser geeignet\nrowwiseDf = pd.read_csv(\"/kaggle/input/rowwisedfcsv/rowwiseDf.csv\")","metadata":{"id":"mytIGQ1gF3fl","executionInfo":{"status":"ok","timestamp":1755367928007,"user_tz":-120,"elapsed":6009,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:14:00.280034Z","iopub.execute_input":"2025-08-22T12:14:00.280340Z","iopub.status.idle":"2025-08-22T12:14:08.828434Z","shell.execute_reply.started":"2025-08-22T12:14:00.280315Z","shell.execute_reply":"2025-08-22T12:14:08.827646Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"gpytorch.settings.cholesky_jitter._global_default = 1e-2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:14:14.802075Z","iopub.execute_input":"2025-08-22T12:14:14.802719Z","iopub.status.idle":"2025-08-22T12:14:14.806412Z","shell.execute_reply.started":"2025-08-22T12:14:14.802691Z","shell.execute_reply":"2025-08-22T12:14:14.805584Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#Input Parameters\nrandomState= 21\nnJobs= -1\nnTrials= 20\n#topK= 3\nnotebook_dir = Path().resolve()\nstoragePath = notebook_dir.parent / \"data\" / \"rowWiseGPModel\"\nStations= [\"Erfurt-Weimar\", \"Schmücke\", \"Eisenach\", \"Artern\", \"Neuhaus am Rennweg\",\"Meiningen\", \"Leinefelde\", \"Osterfeld\"]\nReducedJahre= 5\nminInducing= 1000\nSAVE_DIR = \"/kaggle/working/gp_checkpoints\"\n\nselected_Station = [\"Osterfeld\"] #LastYear wenn letztes Jahr\nfeatures = ['Stationshoehe','geoBreite','geoLaenge', 'hour', 'day_of_year', 'time_hours']\ntargets = ['TT_TU','RF_TU','  R1','  P0','   F']","metadata":{"id":"6ZSzoy1pF0Ti","executionInfo":{"status":"ok","timestamp":1755367921962,"user_tz":-120,"elapsed":68,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:14:16.437787Z","iopub.execute_input":"2025-08-22T12:14:16.438331Z","iopub.status.idle":"2025-08-22T12:14:16.442931Z","shell.execute_reply.started":"2025-08-22T12:14:16.438312Z","shell.execute_reply":"2025-08-22T12:14:16.442196Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"rowwiseDf['MESS_DATUM']= pd.to_datetime(rowwiseDf['MESS_DATUM'])\n\nrowwiseDf['day_of_year']= rowwiseDf['MESS_DATUM'].dt.dayofyear","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:14:21.287312Z","iopub.execute_input":"2025-08-22T12:14:21.288146Z","iopub.status.idle":"2025-08-22T12:14:21.708994Z","shell.execute_reply.started":"2025-08-22T12:14:21.288114Z","shell.execute_reply":"2025-08-22T12:14:21.708174Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"rowwiseDf.columns","metadata":{"id":"3xEkeXFBF5K1","executionInfo":{"status":"ok","timestamp":1755367928039,"user_tz":-120,"elapsed":30,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"outputId":"9ed021b7-628d-4fb2-f206-4166e71734af","trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:14:23.341630Z","iopub.execute_input":"2025-08-22T12:14:23.342183Z","iopub.status.idle":"2025-08-22T12:14:23.348569Z","shell.execute_reply.started":"2025-08-22T12:14:23.342162Z","shell.execute_reply":"2025-08-22T12:14:23.347957Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Index(['MESS_DATUM', 'STATIONS_ID', 'TT_TU', 'RF_TU', '  R1', 'RS_IND', 'WRTR',\n       '   P', '  P0', '   F', '   D', 'Stationshoehe', 'geoBreite',\n       'geoLaenge', 'Stationsname', 'hour', 'day', 'month', 'hour_sin',\n       'hour_cos', 'month_sin', 'month_cos', 'day_of_year_sin',\n       'day_of_year_cos', 'day_of_year'],\n      dtype='object')"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"distanceDf= rowwiseDf[['geoBreite', 'geoLaenge', 'Stationshoehe', 'Stationsname', 'STATIONS_ID']].drop_duplicates()","metadata":{"id":"L-D96LjVF6yH","executionInfo":{"status":"ok","timestamp":1755367928935,"user_tz":-120,"elapsed":898,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:15:23.652320Z","iopub.execute_input":"2025-08-22T12:15:23.652619Z","iopub.status.idle":"2025-08-22T12:15:23.863817Z","shell.execute_reply.started":"2025-08-22T12:15:23.652601Z","shell.execute_reply":"2025-08-22T12:15:23.863030Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(distanceDf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:15:26.505191Z","iopub.execute_input":"2025-08-22T12:15:26.505485Z","iopub.status.idle":"2025-08-22T12:15:26.512584Z","shell.execute_reply.started":"2025-08-22T12:15:26.505440Z","shell.execute_reply":"2025-08-22T12:15:26.511955Z"}},"outputs":[{"name":"stdout","text":"         geoBreite  geoLaenge  Stationshoehe          Stationsname  \\\n0          50.3066    10.9679            344  Lautertal-Oberlauter   \n87648      51.7234    10.6021            607             Braunlage   \n175296     51.5002     9.9507            167             Göttingen   \n262944     50.3123    11.8760            565                   Hof   \n350592     50.4973     9.9427            920           Wasserkuppe   \n438240     50.9829    10.9608            316         Erfurt-Weimar   \n525888     50.8520     9.7377            272         Hersfeld, Bad   \n613536     50.4818    12.1300            387                Plauen   \n701184     51.8454    10.7686            233           Wernigerode   \n788832     51.3932    10.3123            356            Leinefelde   \n876480     51.3744    11.2920            164                Artern   \n964128     50.8812    12.1289            311         Gera-Leumnitz   \n1051776    50.6545    10.7696            938              Schmücke   \n1139424    50.5611    10.3771            450             Meiningen   \n1227072    51.6520    11.1366            404            Harzgerode   \n1314720    51.0872    11.9293            244             Osterfeld   \n1402368    50.5003    11.1345            845    Neuhaus am Rennweg   \n1490016    50.5679    11.8041            501               Schleiz   \n1577664    51.0007    10.3621            312              Eisenach   \n\n         STATIONS_ID  \n0              867.0  \n87648          656.0  \n175296        1691.0  \n262944        2261.0  \n350592        5371.0  \n438240        1270.0  \n525888        2171.0  \n613536        3946.0  \n701184        5490.0  \n788832        2925.0  \n876480         198.0  \n964128        1612.0  \n1051776       4501.0  \n1139424       3231.0  \n1227072       2044.0  \n1314720       3821.0  \n1402368       3513.0  \n1490016       4464.0  \n1577664       7368.0  \n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"lat1 = None\nlon1 = None\nfor _, row in distanceDf.iterrows():\n    if row['Stationsname'] == 'Erfurt-Weimar':\n        lat1 = np.radians(row['geoBreite'])\n        lon1 = np.radians(row['geoLaenge'])\n        break  # reicht, wenn wir den ersten passenden Eintrag haben\n\n# 2. Distanz für alle anderen Stationen berechnen\ndistances = []\nfor _, row in distanceDf.iterrows():\n    if row['Stationsname'] == 'Erfurt-Weimar':\n        continue\n\n    lat2 = np.radians(row['geoBreite'])\n    lon2 = np.radians(row['geoLaenge'])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n\n    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n    distance = 2 * 6371 * np.arcsin(np.sqrt(a))  # in km\n\n    distances.append({\n        'Stationsname': row['Stationsname'],\n        'distance_km': distance\n    })\n\n# 3. In DataFrame umwandeln und sortieren\ndistance_result = pd.DataFrame(distances).sort_values('distance_km')\nprint(distance_result)","metadata":{"id":"X8GTb-wKF8ij","executionInfo":{"status":"ok","timestamp":1755367929023,"user_tz":-120,"elapsed":67,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"outputId":"796c01fd-c2e0-4876-8730-e0de0329e6fd","trusted":true,"execution":{"iopub.status.busy":"2025-08-22T12:14:29.319951Z","iopub.execute_input":"2025-08-22T12:14:29.320529Z","iopub.status.idle":"2025-08-22T12:14:29.334980Z","shell.execute_reply.started":"2025-08-22T12:14:29.320507Z","shell.execute_reply":"2025-08-22T12:14:29.334214Z"}},"outputs":[{"name":"stdout","text":"            Stationsname  distance_km\n11              Schmücke    38.908361\n17              Eisenach    41.949378\n9                 Artern    49.275834\n15    Neuhaus am Rennweg    55.036985\n12             Meiningen    62.326012\n8             Leinefelde    64.219198\n14             Osterfeld    68.707104\n16               Schleiz    75.136254\n0   Lautertal-Oberlauter    75.202795\n13            Harzgerode    75.396944\n10         Gera-Leumnitz    82.636570\n1              Braunlage    86.024839\n5          Hersfeld, Bad    86.966964\n4            Wasserkuppe    89.710348\n2              Göttingen    90.844191\n7            Wernigerode    96.827360\n3                    Hof    98.609755\n6                 Plauen    99.376594\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#reduziere Daten größe damit Modell berechnbar bleibt\nreducedDf= rowwiseDf.copy()\nreducedDf['MESS_DATUM']= pd.to_datetime(reducedDf['MESS_DATUM'])\n\nmaxDate= reducedDf['MESS_DATUM'].max()\ncutoffDate= maxDate - pd.DateOffset(years= ReducedJahre)\n\nreducedDf= reducedDf[(reducedDf['Stationsname'].isin(Stations)) & (reducedDf['MESS_DATUM'] >= cutoffDate)]","metadata":{"id":"4G59MUkTGCAc","executionInfo":{"status":"ok","timestamp":1755367930801,"user_tz":-120,"elapsed":1762,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reducedDf['time_hours'] = (reducedDf['MESS_DATUM'] - reducedDf['MESS_DATUM'].min()).dt.total_seconds() / 3600","metadata":{"id":"IKiXsplPGB7_","executionInfo":{"status":"ok","timestamp":1755367930804,"user_tz":-120,"elapsed":1,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#month wird gedropt da hoch koriliert mit day of year","metadata":{"id":"zA9cDuvTGHGR","executionInfo":{"status":"ok","timestamp":1755367930807,"user_tz":-120,"elapsed":1,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reducedDf= reducedDf.drop(columns= ['STATIONS_ID', 'RS_IND', 'WRTR','   P', '   D', 'day', 'month', 'month_sin', 'month_cos', 'hour_sin', 'hour_cos', 'day_of_year_sin', 'day_of_year_cos'])","metadata":{"id":"ql7eYZYsGJMv","executionInfo":{"status":"ok","timestamp":1755367930813,"user_tz":-120,"elapsed":4,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reducedDf.columns","metadata":{"id":"DLbRNsPFGLVr","executionInfo":{"status":"ok","timestamp":1755367930843,"user_tz":-120,"elapsed":18,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"outputId":"1fe5c5f3-34d1-43f8-b05d-f7511601e188","trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(SAVE_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for station in selected_Station:\n    os.makedirs(SAVE_DIR + '/' + station, exist_ok=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultitaskGPModel(ApproximateGP):\n    def __init__(self, num_latents, num_tasks, inducing_points, nu_height, nu_lonlat, daily_period, yearly_period):\n        variational_distribution= gpytorch.variational.CholeskyVariationalDistribution(\n            inducing_points.size(-2), batch_shape=torch.Size([num_latents])\n        )\n\n        variational_strategy= gpytorch.variational.LMCVariationalStrategy(\n            gpytorch.variational.VariationalStrategy(\n                self, inducing_points, variational_distribution, learn_inducing_locations=True\n            ),\n            num_tasks= num_tasks,\n            num_latents= num_latents,\n            latent_dim= -1\n        )\n\n        super().__init__(variational_strategy)\n\n        self.mean_module= gpytorch.means.ConstantMean(batch_shape= torch.Size([num_latents]))\n\n        self.daily_kernel= PeriodicKernel(period_length=daily_period, batch_shape= torch.Size([num_latents]), active_dim=[3])\n        self.yearly_kernel= PeriodicKernel(period_length=yearly_period, batch_shape= torch.Size([num_latents]), active_dim=[4])\n        self.hight_kernel= MaternKernel(nu=nu_height, batch_shape= torch.Size([num_latents]), active_dim=[0])\n        self.lonLat_kernel= MaternKernel(nu=nu_lonlat, batch_shape= torch.Size([num_latents]), active_dim=[1,2])\n        self.conter_kernel= RBFKernel(batch_shape= torch.Size([num_latents]), active_dim=[5])\n        \n        self.covar_module= ScaleKernel(\n            AdditiveKernel(\n                self.daily_kernel,\n                self.yearly_kernel,\n                self.lonLat_kernel,\n                self.hight_kernel,\n                self.conter_kernel\n            ),\n            batch_shape= torch.Size([num_latents])\n        )\n\n    def forward(self, x):\n        mean_x= self.mean_module(x)\n        covar_x= self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective(trial, X_train_np, y_train_np, X_val_np, y_val_np,\n              num_tasks=5, device=device, save_dir=SAVE_DIR, batch_size=512):\n    # Optuna hyperparams (add or remove as you like)\n    num_inducing = 1000\n    nu_lonlat = 1.5\n    nu_height = 0.5\n    daily_period = 24\n    yearly_period = 365.25\n    lr = 0.0037427697892870536\n    training_iter = 129\n    num_latents = 6\n\n    # Create inducing points (from X_sub)\n    subset_idx = np.random.choice(X_train_np.shape[0], min(10000, X_train_np.shape[0]), replace=False)\n    X_kmeans_np = X_train_np[subset_idx]\n\n    kmeans = KMeans(n_clusters=num_inducing, n_init=10, random_state=randomState)\n    kmeans.fit(X_kmeans_np)\n    inducing_points = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32).to(device)\n\n    # Convert to tensors\n    X_sub = torch.tensor(X_train_np, dtype=torch.float32).to(device)\n    y_sub = torch.tensor(y_train_np, dtype=torch.float32).to(device)\n\n    dataset = TensorDataset(X_sub, y_sub)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    \n    # Build model & likelihood\n    # Pass period_lengths into kernel by setting them after init\n    model = MultitaskGPModel(\n        inducing_points=inducing_points,\n        num_tasks=num_tasks,\n        num_latents= num_latents,\n        nu_lonlat=nu_lonlat,\n        nu_height=nu_height,\n        daily_period= daily_period,\n        yearly_period= yearly_period\n    ).to(device)\n\n    likelihood = MultitaskGaussianLikelihood(num_tasks=num_tasks).to(device)\n\n    # ⬇️ Multi-GPU Wrapper\n    if torch.cuda.device_count() > 1:\n        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n        model = torch.nn.DataParallel(model)\n        likelihood = torch.nn.DataParallel(likelihood)\n        \n    # initialize noise to a sensible positive value to help stability\n    try:\n        likelihood.noise_covar.initialize(noise=0.05)\n    except Exception:\n        pass\n\n    model.train()\n    likelihood.train()\n\n    optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': likelihood.parameters()}], lr=lr)\n\n    if isinstance(model, torch.nn.DataParallel):\n        mll = VariationalELBO(likelihood.module, model.module, num_data=X_sub.shape[0])\n    else:\n        mll = VariationalELBO(likelihood, model, num_data=X_sub.shape[0])\n    #mll = VariationalELBO(likelihood, model, num_data=X_sub.shape[0])\n\n    best_loss = float(\"inf\")\n    accumulation_steps = 2 \n    try:\n        for it in range(training_iter):\n            epoch_loss = 0.0\n            scaler = GradScaler()\n            for X_batch, y_batch in loader:\n                optimizer.zero_grad()\n                with autocast():\n                    # increase jitter during training for robustness\n                    with gpytorch.settings.cholesky_jitter(1e-3):\n                        output = model(X_batch)\n                        loss = -mll(output, y_batch)\n                # catch NaN\n                if not torch.isfinite(loss):\n                    raise RuntimeError(\"Loss NaN or INF\")\n\n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n                #loss.backward()\n                #optimizer.step()\n                epoch_loss += loss.item() * X_batch.size(0)\n\n            # mittlere Epoche\n            epoch_loss /= len(dataset)\n            if epoch_loss < best_loss:\n                best_loss = epoch_loss\n\n            del X_batch, y_batch, output, loss\n            torch.cuda.empty_cache()\n            gc.collect()\n\n        # Validation\n        model.eval()\n        likelihood.eval()\n        total_val_loss = 0.0\n        with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.cholesky_jitter(1e-3):\n            X_val = torch.tensor(X_val_np, dtype=torch.float32).to(device)\n            y_val = torch.tensor(y_val_np, dtype=torch.float32).to(device)\n            for start_idx in range(0, X_val.shape[0], batch_size):\n                end_idx = min(start_idx + batch_size, X_val.shape[0])\n                X_batch = torch.tensor(X_val_np[start_idx:end_idx], dtype=torch.float32).to(device)\n                y_batch = torch.tensor(y_val_np[start_idx:end_idx], dtype=torch.float32).to(device)\n                \n                # Vorwärtsdurchlauf und Verlustberechnung\n                val_output = model(X_batch)\n                val_loss = -mll(val_output, y_batch).item()\n        \n                # Addiere den Verlust für diese Batch\n                total_val_loss += val_loss * X_batch.size(0)\n        \n            # Berechne den durchschnittlichen Verlust über alle Batches\n            average_val_loss = total_val_loss / X_val.shape[0]\n    \n    except NotPSDError as e:\n        # numerical issue with PSD — return a large loss so Optuna avoids such hyperparams\n        print(\"NotPSDError in trial:\", e)\n        return 1e6\n    except Exception as e:\n        print(\"Exception during training:\", e)\n        return 1e6\n\n    # Save model state for this trial\n    model_path = os.path.join(save_dir, f\"model_trial_{trial.number}.pt\")\n    lik_path = os.path.join(save_dir, f\"likelihood_trial_{trial.number}.pt\")\n    if isinstance(model, torch.nn.DataParallel):\n        torch.save(model.module.state_dict(), model_path)\n        # likelihood ist auch DataParallel → also auch .module\n        torch.save(likelihood.module.state_dict(), lik_path)\n    else:\n        torch.save(model.state_dict(), model_path)\n        torch.save(likelihood.state_dict(), lik_path)\n    print(f\"[Trial {trial.number}] saved to {model_path}\")\n\n    return average_val_loss","metadata":{"id":"oAOu92pdzJ4x","executionInfo":{"status":"ok","timestamp":1755367931422,"user_tz":-120,"elapsed":46,"user":{"displayName":"Johannes","userId":"12063554621520996306"}},"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for station in selected_Station:\n    if station == 'LastYear':\n        # Split nach Datum: letzte 10% als Test\n        maxDate = reducedDf['MESS_DATUM'].max()\n        cutoffDate = maxDate - pd.DateOffset(years=1)\n        df_test = reducedDf[reducedDf['MESS_DATUM'] >= cutoffDate]\n        df_train = reducedDf[reducedDf['MESS_DATUM'] < cutoffDate]\n        station_name = \"None\"\n    else:\n        # Split nach Station\n        df_test = reducedDf[reducedDf['Stationsname'] == station]\n        df_train = reducedDf[reducedDf['Stationsname'] != station]\n        station_name = station\n\n    drop_cols = ['MESS_DATUM', 'Stationsname']\n    df_train = df_train.drop(columns=drop_cols, errors='ignore')\n    df_test = df_test.drop(columns=drop_cols, errors='ignore')\n\n    X_train= df_train[features].values.astype(np.float32)\n    y_train= df_train[targets].values.astype(np.float32)\n\n    X_test= df_test[features].values.astype(np.float32)\n    y_test= df_test[targets].values.astype(np.float32)\n\n    scalerX = StandardScaler()\n    X_train_np = scalerX.fit_transform(X_train)\n    X_val_np = scalerX.transform(X_test)\n    scalerY = StandardScaler()\n    y_train_np = scalerY.fit_transform(y_train)\n    y_val_np = scalerY.transform(y_test)\n\n    objective_fn = partial(\n        objective,\n        X_train_np=X_train_np,\n        y_train_np=y_train_np,\n        X_val_np=X_val_np,\n        y_val_np=y_val_np,\n        num_tasks= len(targets),          # Anzahl Output-Tasks\n        device=device,\n        save_dir=SAVE_DIR + '/' + station\n    )\n\n    storage_path = f\"sqlite:///{SAVE_DIR}/{station}.db\"\n    study = optuna.create_study(\n        study_name=\"sparse_gp_weather\",\n        storage=storage_path,\n        direction=\"minimize\",\n        load_if_exists=True,\n    )\n    study.optimize(objective_fn, n_trials=1)# Optuna-Studie mit persistentem Speicher","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-22T08:23:24.207Z"}},"outputs":[],"execution_count":null}]}